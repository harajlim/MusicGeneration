{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install music21\n",
    "!{sys.executable} -m pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harajlim/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodings/information.pickle','rb') as file:\n",
    "    DF=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF[DF['Artist']=='chopin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 4317.63it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "#we create a dict to translate each vocab element to a number and vice versa:\n",
    "WordToNumber={}\n",
    "NumberToWord={}\n",
    "\n",
    "GfToNumber={}\n",
    "NumberToGf={}\n",
    "\n",
    "NoteToNumber={}\n",
    "NumberToNote={}\n",
    "\n",
    "\n",
    "gf_index=0\n",
    "note_index=0\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    WordToNumber[word]=i\n",
    "    NumberToWord[i]=word\n",
    "    if 'gf' in str(word):\n",
    "        GfToNumber[word]=gf_index\n",
    "        NumberToGf[gf_index]=word\n",
    "        gf_index+=1\n",
    "    else:\n",
    "        NoteToNumber[word]=note_index\n",
    "        NumberToNote[note_index]=word\n",
    "        note_index+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_gf_or_note(DF, n_vocab,WordToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            if 'gf' not in str(sequence_in[-1]):\n",
    "                sequence_out = float('gf' in str(song[i + sequence_length]))\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(sequence_out)\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_gf(DF, n_vocab,WordToNumber,GfToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(GfToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_note(DF, n_vocab,WordToNumber,NoteToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' not in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(NoteToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_gf_or_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_gf(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 34.00it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 59.05it/s] \n",
      "100%|██████████| 48/48 [00:01<00:00, 41.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#we first need to load the trained models:\n",
    "\n",
    "gf_or_note_input,gf_or_note_output=prepare_sequences_gf_or_note(DF,len(WordToNumber),WordToNumber)\n",
    "get_gf_input,get_gf_output=prepare_sequences_get_gf(DF,len(WordToNumber),WordToNumber,GfToNumber)\n",
    "get_note_input,get_note_output=prepare_sequences_get_note(DF,len(WordToNumber),WordToNumber,NoteToNumber)\n",
    "\n",
    "gf_or_note=create_network_gf_or_note(gf_or_note_input,gf_or_note_output.shape[1])\n",
    "gf_or_note.load_weights('SavedModels/weights.gf_or_note.hdf5')\n",
    "get_gf=create_network_get_gf(get_gf_input,get_gf_output.shape[1])\n",
    "get_gf.load_weights('SavedModels/weights.get_gf.hdf5')\n",
    "get_note=create_network_get_note(get_note_input,get_note_output.shape[1])\n",
    "get_note.load_weights('SavedModels/weights.get_note.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have all three models. We start with a sequence:\n",
    "#We pick the beggining of the first song in our DF: chpn-p1:\n",
    "encoding=DF.iloc[4,2]\n",
    "sequenceIn=[]\n",
    "\n",
    "for word in encoding[:100]:\n",
    "    sequenceIn.append(WordToNumber[word])\n",
    "FullSequnce=sequenceIn\n",
    "\n",
    "for i in range(100):\n",
    "    if 'gf' in str(NumberToWord[sequenceIn[-1]]):\n",
    "        next_note=get_note.predict(np.reshape(sequenceIn,(1,100,1)))\n",
    "        next_note=np.argmax(next_note)\n",
    "        next_note=NumberToNote[next_note]\n",
    "        next_note=WordToNumber[next_note]\n",
    "        FullSequnce.append(next_note)\n",
    "    else:\n",
    "        nextStep=gf_or_note.predict(np.reshape(sequenceIn,(1,100,1)))\n",
    "        nextStep=np.argmax(nextStep)\n",
    "        #we get nextStep=1 if next step is a gf and 0 if note\n",
    "        if nextStep==0:\n",
    "            next_note=get_note.predict(np.reshape(sequenceIn,(1,100,1)))\n",
    "            next_note=np.argmax(next_note)\n",
    "            next_note=NumberToNote[next_note]\n",
    "            next_note=WordToNumber[next_note]\n",
    "            FullSequnce.append(next_note)\n",
    "        else:\n",
    "            next_gf=get_gf.predict(np.reshape(sequenceIn,(1,100,1)))\n",
    "            next_gf=np.argmax(next_gf)\n",
    "            next_gf=NumberToGf[next_gf]\n",
    "            next_gf=WordToNumber[next_gf]\n",
    "            FullSequnce.append(next_gf)\n",
    "    sequenceIn=FullSequnce[-100:]\n",
    "            \n",
    "Composition=[]            \n",
    "for number in FullSequnce:\n",
    "    Composition.append(NumberToWord[number])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we write a function that takes in a sequence of events and changes it into a midi file:\n",
    "def write_midi(composition,filename):\n",
    "    MidiSequence=[]\n",
    "    Offset=0\n",
    "    for word in composition:\n",
    "        if 'gf' in str(word):\n",
    "            Offset+=float(word[2:])\n",
    "        else:\n",
    "            new_note=music21.note.Note(int(word))\n",
    "            new_note.offset=Offset\n",
    "            new_note.storedInstrument=music21.instrument.Piano()\n",
    "            MidiSequence.append(new_note)\n",
    "            \n",
    "    midi_stream=music21.stream.Stream(MidiSequence)\n",
    "    midi_stream.write('midi', fp=filename)    \n",
    "    \n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_midi(Composition,'Samples/ChopinOnly.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 54,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 54,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 54,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 37,\n",
       " 65,\n",
       " 71,\n",
       " 'gf0.5',\n",
       " 55,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 59,\n",
       " 68,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 54,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.5',\n",
       " 56,\n",
       " 'gf0.5',\n",
       " 54,\n",
       " 'gf0.5',\n",
       " 58,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 49,\n",
       " 'gf0.5',\n",
       " 42,\n",
       " 61,\n",
       " 66,\n",
       " 70,\n",
       " 'gf0.5',\n",
       " 53,\n",
       " 'gf0.1667',\n",
       " 68,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 57,\n",
       " 'gf8.0',\n",
       " 57,\n",
       " 'gf8.0',\n",
       " 57,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 69,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 52,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58,\n",
       " 'gf8.0',\n",
       " 58]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
