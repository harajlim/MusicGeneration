{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install music21\n",
    "!{sys.executable} -m pip install tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(filename):\n",
    "    \"\"\"Encodes song in filename. See milestone1 report for encoding\"\"\"\n",
    "    notesRaw=music21.converter.parse(filename)\n",
    "    notesRaw=notesRaw.flat.notes\n",
    "        \n",
    "    pitches=[]\n",
    "    offsets=[]\n",
    "        \n",
    "    for note in notesRaw:\n",
    "        if isinstance(note,music21.note.Note):\n",
    "            pitches.append(note.pitch.midi)\n",
    "            offsets.append(note.offset)\n",
    "        else:\n",
    "            chordNotes=[int(b.midi) for b in note.pitches]\n",
    "            pitches.extend(chordNotes)\n",
    "            offsets.extend([note.offset]*len(chordNotes))\n",
    "\n",
    "    pitches=np.array(pitches)\n",
    "    offsets=np.array(offsets)\n",
    "    uniqueSortedOffsets=np.sort(np.unique(offsets))\n",
    "    \n",
    "    encoding=[]\n",
    "    \n",
    "    for i in range(len(uniqueSortedOffsets)-1):\n",
    "        time=uniqueSortedOffsets[i]\n",
    "        pitchesHere=pitches[offsets==time]\n",
    "        goforward='gf'+str(uniqueSortedOffsets[i+1]-time)\n",
    "        \n",
    "        encoding.extend(list(np.sort(pitchesHere)))\n",
    "        encoding.append(goforward)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return encoding   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_song(song,filename):\n",
    "    \"\"\"Decodes song encoded by encode_song(). song is an encoded song of type list, and filename is\n",
    "    the path where the new decoded midi file is to reside\"\"\"\n",
    "    stream=[]\n",
    "    offset=0\n",
    "    for event in song:\n",
    "        if 'gf' in str(event):\n",
    "            offset+=float(event[2:])\n",
    "        else:\n",
    "            newNote=music21.note.Note(int(event))\n",
    "            newNote.offset=offset\n",
    "            newNote.storedInstrument=music21.instrument.Piano()\n",
    "            stream.append(newNote)\n",
    "    midi_stream=music21.stream.Stream(stream)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "    return 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get the the directories of all the songs in our dataset. \n",
    "\n",
    "artists=glob.glob('Music/*') #files are sorted via artist\n",
    " \n",
    "songs=[] #the song filename\n",
    "\n",
    "for artist in artists:\n",
    "    songs.extend(glob.glob(artist+'/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we encode each song, save them in a dataframe, and then pickle the dataframe.\n",
    "information=defaultdict(list)\n",
    "\n",
    "for song in tqdm(songs):\n",
    "    encoded=encode_song(song)\n",
    "    _,artist,songname=song.split('\\\\')\n",
    "    information['SongName'].append(songname)\n",
    "    information['Artist'].append(artist)\n",
    "    information['Encoded'].append(encoded)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_to_save=pd.DataFrame.from_dict(information)\n",
    "DF_to_save.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF_to_save\n",
    "DF_to_save=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we first get all the unique elements of our vocabulary:\n",
    "\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "    \n",
    "#we separate the notesOnly from gfOnly\n",
    "notesOnly=[]\n",
    "gfOnly=[]\n",
    "\n",
    "for word in vocab:\n",
    "\n",
    "    if 'gf' in str(word):\n",
    "        gfOnly.append(word)\n",
    "    else:\n",
    "        notesOnly.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check to see what is the quarter lengths duration of the unique go forward events. seems like sometimes\n",
    "#when changin\n",
    "numbers=[]\n",
    "for gf in gfOnly:\n",
    "    if '/' in gf:\n",
    "        num,denom=gf.split('/')\n",
    "        num=num[2:]\n",
    "        numbers.append(float(num)/float(denom))\n",
    "    else:\n",
    "        numbers.append(float(gf[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sorted(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we see that alot of the unique offsets are essentially the same but differ slightly due to representation by the author of the midi file. We thus have to fix something in the representation of the gfs. This is something we could have fixed in the encode_song function. However to avoid having to open the files again, we ammend the issue in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewColumn=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    encoding=DF.iloc[i,2]\n",
    "    #now loop through every word of the encoding\n",
    "    replacement=[]\n",
    "    for i,word in enumerate(encoding):\n",
    "        if 'gf' in str(word):\n",
    "            #we have a gf, we isolate the word from the letters 'gf'\n",
    "            keep=word[2:]\n",
    "            #we now check to see if there is a division symbol:\n",
    "            if '/' in keep:\n",
    "                numerator,denominator=keep.split('/')\n",
    "                keep=np.round(float(numerator)/float(denominator),4)\n",
    "                replacement.append('gf'+str(keep))\n",
    "            else:\n",
    "                replacement.append('gf'+str(np.round(float(keep),4)))\n",
    "                \n",
    "        else:\n",
    "            #its just a note.\n",
    "            replacement.append(word)\n",
    "    NewColumn.append(replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['ModedEncoded']=NewColumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF.drop(columns='Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('encodings/information.pickle','wb') as file:\n",
    "    pickle.dump(DF,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
