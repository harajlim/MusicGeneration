{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install music21\n",
    "!{sys.executable} -m pip install tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n",
    "\n",
    "We write functions to:\n",
    "\n",
    "1- Encode Each song.\n",
    "\n",
    "2- Decode each song and save it as midi.\n",
    "\n",
    "3- Obtain a dict that translates each event into a numerical value.\n",
    "\n",
    "4- Prepare input sequences and outputs for the three LSTMs to be trained.\n",
    "\n",
    "5- Train the LSTMs.\n",
    "\n",
    "6- Use the three trained LSTMs to generate music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MHarajli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(filename):\n",
    "    \"\"\"Encodes song in filename. See milestone1 report for encoding\"\"\"\n",
    "    notesRaw=music21.converter.parse(filename)\n",
    "    notesRaw=notesRaw.flat.notes\n",
    "        \n",
    "    pitches=[]\n",
    "    offsets=[]\n",
    "        \n",
    "    for note in notesRaw:\n",
    "        if isinstance(note,music21.note.Note):\n",
    "            pitches.append(note.pitch.midi)\n",
    "            offsets.append(note.offset)\n",
    "        else:\n",
    "            chordNotes=[int(b.midi) for b in note.pitches]\n",
    "            pitches.extend(chordNotes)\n",
    "            offsets.extend([note.offset]*len(chordNotes))\n",
    "\n",
    "    pitches=np.array(pitches)\n",
    "    offsets=np.array(offsets)\n",
    "    uniqueSortedOffsets=np.sort(np.unique(offsets))\n",
    "    \n",
    "    encoding=[]\n",
    "    \n",
    "    for i in range(len(uniqueSortedOffsets)-1):\n",
    "        time=uniqueSortedOffsets[i]\n",
    "        pitchesHere=pitches[offsets==time]\n",
    "        goforward='gf'+str(uniqueSortedOffsets[i+1]-time)\n",
    "        \n",
    "        encoding.extend(list(np.sort(pitchesHere)))\n",
    "        encoding.append(goforward)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return encoding   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_song(song,filename):\n",
    "    \"\"\"Decodes song encoded by encode_song(). song is an encoded song of type list, and filename is\n",
    "    the path where the new decoded midi file is to reside\"\"\"\n",
    "    stream=[]\n",
    "    offset=0\n",
    "    for event in song:\n",
    "        if 'gf' in str(event):\n",
    "            offset+=float(event[2:])\n",
    "        else:\n",
    "            newNote=music21.note.Note(int(event))\n",
    "            newNote.offset=offset\n",
    "            newNote.storedInstrument=music21.instrument.Piano()\n",
    "            stream.append(newNote)\n",
    "    midi_stream=music21.stream.Stream(stream)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "    return 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get the the directories of all the songs in our dataset. \n",
    "\n",
    "artists=glob.glob('Music/*') #files are sorted via artist\n",
    " \n",
    "songs=[] #the song filename\n",
    "\n",
    "for artist in artists:\n",
    "    songs.extend(glob.glob(artist+'/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 266/266 [28:20<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#we encode each song, save them in a dataframe, and then pickle the dataframe.\n",
    "information=defaultdict(list)\n",
    "\n",
    "for song in tqdm(songs):\n",
    "    encoded=encode_song(song)\n",
    "    _,artist,songname=song.split('\\\\')\n",
    "    information['SongName'].append(songname)\n",
    "    information['Artist'].append(artist)\n",
    "    information['Encoded'].append(encoded)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_to_save=pd.DataFrame.from_dict(information)\n",
    "DF_to_save.head()\n",
    "\n",
    "with open('encodings/information.pickle','wb') as file:\n",
    "    pickle.dump(DF_to_save,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF_to_save\n",
    "DF_to_save=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 266/266 [00:00<00:00, 3410.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#inWhat follows we create three dictionaries: one for notes and gf (which will be used in the input)\n",
    "#another for just gfs (output of get_gf), and another for just notes (for get_note)\n",
    "\n",
    "#we first get all the unique elements of our vocabulary:\n",
    "\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "    \n",
    "notesOnly=[]\n",
    "gfOnly=[]\n",
    "\n",
    "for word in vocab:\n",
    "\n",
    "    if 'gf' in str(word):\n",
    "        gfOnly.append(word)\n",
    "    else:\n",
    "        notesOnly.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check to see what is the quarter lengths duration of the unique go forward events\n",
    "numbers=[]\n",
    "for gf in gfOnly:\n",
    "    if '/' in gf:\n",
    "        num,denom=gf.split('/')\n",
    "        num=num[2:]\n",
    "        numbers.append(float(num)/float(denom))\n",
    "    else:\n",
    "        numbers.append(float(gf[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08333333333325754, 0.08333333333331439, 0.0833333333333286, 0.08333333333333215, 0.08333333333333304, 0.08333333333333326, 0.08333333333333331, 0.08333333333333337, 0.08333333333333348, 0.08333333333333393, 0.0833333333333357, 0.08333333333334281, 0.08333333333337123, 0.16666666666662877, 0.1666666666666572, 0.1666666666666643, 0.16666666666666607, 0.16666666666666652, 0.16666666666666663, 0.16666666666666669, 0.16666666666666674, 0.16666666666666696, 0.16666666666666785, 0.1666666666666714, 0.16666666666668561, 0.16666666666674246, 0.25, 0.33333333333325754, 0.3333333333333144, 0.3333333333333286, 0.33333333333333215, 0.33333333333333304, 0.33333333333333326, 0.3333333333333333, 0.3333333333333333, 0.33333333333333337, 0.3333333333333335, 0.3333333333333339, 0.3333333333333357, 0.3333333333333428, 0.33333333333337123, 0.41666666666662877, 0.4166666666666572, 0.4166666666666643, 0.41666666666666663, 0.41666666666666785, 0.4166666666666714, 0.4166666666666856, 0.5, 0.6666666666666288, 0.6666666666666572, 0.6666666666666643, 0.6666666666666661, 0.6666666666666665, 0.6666666666666666, 0.6666666666666667, 0.666666666666667, 0.6666666666666679, 0.6666666666666714, 0.6666666666666856, 0.6666666666667425, 0.75, 0.8333333333332575, 0.8333333333333144, 0.8333333333333286, 0.8333333333333321, 0.833333333333333, 0.8333333333333339, 0.8333333333333357, 0.8333333333333428, 0.8333333333333712, 0.9166666666666572, 1.0, 1.0, 1.0833333333332575, 1.0833333333333428, 1.1666666666666572, 1.1666666666666643, 1.1666666666666714, 1.1666666666666856, 1.25, 1.3333333333332575, 1.3333333333333144, 1.3333333333333286, 1.3333333333333321, 1.3333333333333428, 1.3333333333333712, 1.416666666666666, 1.5, 1.5833333333333144, 1.583333333333333, 1.6666666666666288, 1.6666666666666572, 1.6666666666666714, 1.6666666666667425, 1.75, 1.8333333333333144, 1.8333333333333357, 2.0, 2.0833333333333144, 2.1666666666666714, 2.25, 2.3333333333332575, 2.3333333333333144, 2.333333333333332, 2.3333333333333357, 2.3333333333333712, 2.5, 2.666666666666657, 2.6666666666666643, 2.6666666666666856, 2.75, 2.8333333333333357, 3.0, 3.25, 3.5, 3.666666666666657, 3.6666666666666643, 3.666666666666666, 3.75, 3.8333333333333144, 4.0, 4.25, 4.5, 4.666666666666686, 4.75, 5.0, 5.333333333333371, 5.5, 5.666666666666664, 5.833333333333371, 6.0, 6.25, 6.5, 7.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we see that alot of the unique offsets are essentially the same but differ slightly due to representation by the author of the midi file. We thus have to fix something in the representation of the gfs. This is something we could have fixed in the encode_song function. However to avoid having to open the files again, we ammend the issue in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 266/266 [00:03<00:00, 76.09it/s]\n"
     ]
    }
   ],
   "source": [
    "NewColumn=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    encoding=DF.iloc[i,2]\n",
    "    #now loop through every word of the encoding\n",
    "    replacement=[]\n",
    "    for i,word in enumerate(encoding):\n",
    "        if 'gf' in str(word):\n",
    "            #we have a gf, we isolate the word from the letters 'gf'\n",
    "            keep=word[2:]\n",
    "            #we now check to see if there is a division symbol:\n",
    "            if '/' in keep:\n",
    "                numerator,denominator=keep.split('/')\n",
    "                keep=np.round(float(numerator)/float(denominator),4)\n",
    "                replacement.append('gf'+str(keep))\n",
    "            else:\n",
    "                replacement.append('gf'+str(np.round(float(keep),4)))\n",
    "                \n",
    "        else:\n",
    "            #its just a note.\n",
    "            replacement.append(word)\n",
    "    NewColumn.append(replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['ModedEncoded']=NewColumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF.drop(columns='Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodings/information.pickle','wb') as file:\n",
    "    pickle.dump(DF,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodings/information.pickle','rb') as file:\n",
    "    DF=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ModedEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alb_esp1.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[57, 81, gf0.5, 64, 88, gf3.25, 62, 86, gf0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alb_esp2.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[38, 50, gf0.75, 57, gf0.25, 62, 66, 69, gf0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alb_esp3.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[59, 71, gf0.5, 63, 75, gf0.5, 66, 78, gf0.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alb_esp4.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[79, gf0.5, 71, 74, gf0.5, 72, 75, gf0.5, 69, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alb_esp5.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[51, 58, gf0.5, 58, gf1.0, 58, gf0.5, 51, 58, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SongName   Artist                                       ModedEncoded\n",
       "0  alb_esp1.mid  albeniz  [57, 81, gf0.5, 64, 88, gf3.25, 62, 86, gf0.08...\n",
       "1  alb_esp2.mid  albeniz  [38, 50, gf0.75, 57, gf0.25, 62, 66, 69, gf0.5...\n",
       "2  alb_esp3.mid  albeniz  [59, 71, gf0.5, 63, 75, gf0.5, 66, 78, gf0.5, ...\n",
       "3  alb_esp4.mid  albeniz  [79, gf0.5, 71, 74, gf0.5, 72, 75, gf0.5, 69, ...\n",
       "4  alb_esp5.mid  albeniz  [51, 58, gf0.5, 58, gf1.0, 58, gf0.5, 51, 58, ..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF[DF['Artist']=='chopin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF.iloc[[0,1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#we first get all the unique elements of our vocabulary:\n",
    "\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "    \n",
    "notesOnly=[]\n",
    "gfOnly=[]\n",
    "\n",
    "for word in vocab:\n",
    "\n",
    "    if 'gf' in str(word):\n",
    "        gfOnly.append(word)\n",
    "    else:\n",
    "        notesOnly.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0833, 0.1667, 0.25]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check to see what is the quarter lengths duration of the unique go forward events\n",
    "numbers=[]\n",
    "for gf in gfOnly:\n",
    "    if '/' in gf:\n",
    "        num,denom=gf.split('/')\n",
    "        num=num[2:]\n",
    "        numbers.append(float(num)/float(denom))\n",
    "    else:\n",
    "        numbers.append(float(gf[2:]))\n",
    "sorted(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now can start preparing inputs and outputs for the various neural networks we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#first step is getting a representation of the vocabulary:\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a dict to translate each vocab element to a number and vice versa:\n",
    "WordToNumber={}\n",
    "NumberToWord={}\n",
    "\n",
    "GfToNumber={}\n",
    "NumberToGf={}\n",
    "\n",
    "NoteToNumber={}\n",
    "NumberToNote={}\n",
    "\n",
    "\n",
    "gf_index=0\n",
    "note_index=0\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    WordToNumber[word]=i\n",
    "    NumberToWord[i]=word\n",
    "    if 'gf' in str(word):\n",
    "        GfToNumber[word]=gf_index\n",
    "        NumberToGf[gf_index]=word\n",
    "        gf_index+=1\n",
    "    else:\n",
    "        NoteToNumber[word]=note_index\n",
    "        NumberToNote[note_index]=word\n",
    "        note_index+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Architecture:\n",
    "\n",
    "We have 3 neural networks:\n",
    "\n",
    "1- gf_or_note\n",
    "\n",
    "2- get_gf\n",
    "\n",
    "3- get_note\n",
    "\n",
    "\n",
    "\n",
    "The inputs for all three of the nets are in the same space and have the same representation. The outputs differ. The output of gf_or_note is binary, the output of get_gf is limited to the different available gf's while the output of get_note is limited to the keys on the piano.\n",
    "\n",
    "We begin by getting a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_gf_or_note(DF, n_vocab,WordToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            if 'gf' not in str(sequence_in[-1]):\n",
    "                sequence_out = float('gf' in str(song[i + sequence_length]))\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(sequence_out)\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 100, 1)\n",
      "(521, 2)\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_gf_or_note(DF,len(WordToNumber),WordToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_gf(DF, n_vocab,WordToNumber,GfToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(GfToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 128.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 100, 1)\n",
      "(290, 6)\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_get_gf(DF,len(WordToNumber),WordToNumber,GfToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_note(DF, n_vocab,WordToNumber,NoteToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' not in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(NoteToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 100, 1)\n",
      "(519, 60)\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_get_note(DF,len(WordToNumber),WordToNumber,NoteToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_gf_or_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(20,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_gf(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(20,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(20,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def train_gf_or_note(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.gf_or_note.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_get_gf(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.get_gf.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_get_note(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.get_note.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 128.21it/s]\n",
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences Prepared, creating models\n",
      "Models Created, training in progress\n",
      "Epoch 1/500\n",
      "521/521 [==============================] - 4s 9ms/step - loss: 0.6979 - acc: 0.4760\n",
      "Epoch 2/500\n",
      "521/521 [==============================] - 0s 837us/step - loss: 0.6894 - acc: 0.5566\n",
      "Epoch 3/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.6908 - acc: 0.5566\n",
      "Epoch 4/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.6863 - acc: 0.5566\n",
      "Epoch 5/500\n",
      "521/521 [==============================] - 0s 887us/step - loss: 0.6861 - acc: 0.5547\n",
      "Epoch 6/500\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.6861 - acc: 0.5547\n",
      "Epoch 7/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.6871 - acc: 0.5643\n",
      "Epoch 8/500\n",
      "521/521 [==============================] - 0s 924us/step - loss: 0.6869 - acc: 0.5643\n",
      "Epoch 9/500\n",
      "521/521 [==============================] - 0s 918us/step - loss: 0.6846 - acc: 0.5681\n",
      "Epoch 10/500\n",
      "521/521 [==============================] - 0s 859us/step - loss: 0.6840 - acc: 0.5566\n",
      "Epoch 11/500\n",
      "521/521 [==============================] - 0s 873us/step - loss: 0.6840 - acc: 0.5566\n",
      "Epoch 12/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6841 - acc: 0.5566\n",
      "Epoch 13/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6822 - acc: 0.5566\n",
      "Epoch 14/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6795 - acc: 0.5566\n",
      "Epoch 15/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6813 - acc: 0.5528\n",
      "Epoch 16/500\n",
      "521/521 [==============================] - 0s 916us/step - loss: 0.6814 - acc: 0.5566\n",
      "Epoch 17/500\n",
      "521/521 [==============================] - 0s 830us/step - loss: 0.6798 - acc: 0.5681\n",
      "Epoch 18/500\n",
      "521/521 [==============================] - 0s 849us/step - loss: 0.6809 - acc: 0.5931\n",
      "Epoch 19/500\n",
      "521/521 [==============================] - 0s 840us/step - loss: 0.6794 - acc: 0.5931\n",
      "Epoch 20/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6805 - acc: 0.5835\n",
      "Epoch 21/500\n",
      "521/521 [==============================] - 0s 924us/step - loss: 0.6794 - acc: 0.5873\n",
      "Epoch 22/500\n",
      "521/521 [==============================] - 0s 838us/step - loss: 0.6784 - acc: 0.5797\n",
      "Epoch 23/500\n",
      "521/521 [==============================] - 0s 835us/step - loss: 0.6767 - acc: 0.5777\n",
      "Epoch 24/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.6747 - acc: 0.5835\n",
      "Epoch 25/500\n",
      "521/521 [==============================] - 0s 868us/step - loss: 0.6749 - acc: 0.6084\n",
      "Epoch 26/500\n",
      "521/521 [==============================] - 0s 823us/step - loss: 0.6752 - acc: 0.5854\n",
      "Epoch 27/500\n",
      "521/521 [==============================] - 0s 830us/step - loss: 0.6717 - acc: 0.5797\n",
      "Epoch 28/500\n",
      "521/521 [==============================] - 0s 879us/step - loss: 0.6690 - acc: 0.6084\n",
      "Epoch 29/500\n",
      "521/521 [==============================] - 0s 843us/step - loss: 0.6725 - acc: 0.6084\n",
      "Epoch 30/500\n",
      "521/521 [==============================] - 0s 841us/step - loss: 0.6673 - acc: 0.6123\n",
      "Epoch 31/500\n",
      "521/521 [==============================] - 0s 919us/step - loss: 0.6735 - acc: 0.6008\n",
      "Epoch 32/500\n",
      "521/521 [==============================] - 0s 922us/step - loss: 0.6708 - acc: 0.6065\n",
      "Epoch 33/500\n",
      "521/521 [==============================] - 0s 810us/step - loss: 0.6701 - acc: 0.6027\n",
      "Epoch 34/500\n",
      "521/521 [==============================] - 0s 820us/step - loss: 0.6697 - acc: 0.6065\n",
      "Epoch 35/500\n",
      "521/521 [==============================] - 0s 859us/step - loss: 0.6663 - acc: 0.6161\n",
      "Epoch 36/500\n",
      "521/521 [==============================] - 0s 854us/step - loss: 0.6667 - acc: 0.5969\n",
      "Epoch 37/500\n",
      "521/521 [==============================] - 0s 854us/step - loss: 0.6658 - acc: 0.6065\n",
      "Epoch 38/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6634 - acc: 0.6046\n",
      "Epoch 39/500\n",
      "521/521 [==============================] - 0s 873us/step - loss: 0.6655 - acc: 0.6123\n",
      "Epoch 40/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.6653 - acc: 0.6123\n",
      "Epoch 41/500\n",
      "521/521 [==============================] - 0s 909us/step - loss: 0.6594 - acc: 0.6238\n",
      "Epoch 42/500\n",
      "521/521 [==============================] - 0s 924us/step - loss: 0.6562 - acc: 0.6238\n",
      "Epoch 43/500\n",
      "521/521 [==============================] - 0s 915us/step - loss: 0.6605 - acc: 0.6142\n",
      "Epoch 44/500\n",
      "521/521 [==============================] - 0s 829us/step - loss: 0.6616 - acc: 0.6104\n",
      "Epoch 45/500\n",
      "521/521 [==============================] - 0s 849us/step - loss: 0.6577 - acc: 0.6257\n",
      "Epoch 46/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6612 - acc: 0.6123\n",
      "Epoch 47/500\n",
      "521/521 [==============================] - 0s 873us/step - loss: 0.6612 - acc: 0.6296\n",
      "Epoch 48/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6537 - acc: 0.6238\n",
      "Epoch 49/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6523 - acc: 0.6276\n",
      "Epoch 50/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6469 - acc: 0.6257\n",
      "Epoch 51/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.6459 - acc: 0.6200\n",
      "Epoch 52/500\n",
      "521/521 [==============================] - 0s 859us/step - loss: 0.6482 - acc: 0.6257\n",
      "Epoch 53/500\n",
      "521/521 [==============================] - 0s 919us/step - loss: 0.6429 - acc: 0.6392\n",
      "Epoch 54/500\n",
      "521/521 [==============================] - 0s 833us/step - loss: 0.6389 - acc: 0.6411\n",
      "Epoch 55/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.6352 - acc: 0.6468\n",
      "Epoch 56/500\n",
      "521/521 [==============================] - 0s 854us/step - loss: 0.6354 - acc: 0.6257\n",
      "Epoch 57/500\n",
      "521/521 [==============================] - 0s 940us/step - loss: 0.6425 - acc: 0.6104\n",
      "Epoch 58/500\n",
      "521/521 [==============================] - 0s 850us/step - loss: 0.6376 - acc: 0.6276\n",
      "Epoch 59/500\n",
      "521/521 [==============================] - 0s 870us/step - loss: 0.6387 - acc: 0.6411\n",
      "Epoch 60/500\n",
      "521/521 [==============================] - 0s 818us/step - loss: 0.6335 - acc: 0.6449\n",
      "Epoch 61/500\n",
      "521/521 [==============================] - 0s 884us/step - loss: 0.6324 - acc: 0.6392\n",
      "Epoch 62/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.6270 - acc: 0.6411\n",
      "Epoch 63/500\n",
      "521/521 [==============================] - 0s 883us/step - loss: 0.6219 - acc: 0.6737\n",
      "Epoch 64/500\n",
      "521/521 [==============================] - 0s 840us/step - loss: 0.6285 - acc: 0.6468\n",
      "Epoch 65/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.6307 - acc: 0.6488\n",
      "Epoch 66/500\n",
      "521/521 [==============================] - 0s 844us/step - loss: 0.6244 - acc: 0.6449\n",
      "Epoch 67/500\n",
      "521/521 [==============================] - 0s 928us/step - loss: 0.6162 - acc: 0.6545\n",
      "Epoch 68/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6113 - acc: 0.6468\n",
      "Epoch 69/500\n",
      "521/521 [==============================] - 0s 864us/step - loss: 0.6142 - acc: 0.6564\n",
      "Epoch 70/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.6117 - acc: 0.6622\n",
      "Epoch 71/500\n",
      "521/521 [==============================] - 0s 945us/step - loss: 0.6089 - acc: 0.6507\n",
      "Epoch 72/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.6047 - acc: 0.6910\n",
      "Epoch 73/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.6069 - acc: 0.6737\n",
      "Epoch 74/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.6057 - acc: 0.6833\n",
      "Epoch 75/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.6065 - acc: 0.6871\n",
      "Epoch 76/500\n",
      "521/521 [==============================] - 0s 859us/step - loss: 0.6032 - acc: 0.6718\n",
      "Epoch 77/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5875 - acc: 0.6775\n",
      "Epoch 78/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.5998 - acc: 0.6411\n",
      "Epoch 79/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.5828 - acc: 0.7006\n",
      "Epoch 80/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.5963 - acc: 0.6967\n",
      "Epoch 81/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.6006 - acc: 0.6795\n",
      "Epoch 82/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5907 - acc: 0.6929\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521/521 [==============================] - 0s 907us/step - loss: 0.5757 - acc: 0.6814\n",
      "Epoch 84/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5806 - acc: 0.7083\n",
      "Epoch 85/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.5690 - acc: 0.7466\n",
      "Epoch 86/500\n",
      "521/521 [==============================] - 1s 965us/step - loss: 0.5854 - acc: 0.7044\n",
      "Epoch 87/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5679 - acc: 0.7063\n",
      "Epoch 88/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5626 - acc: 0.6967\n",
      "Epoch 89/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.5596 - acc: 0.7159\n",
      "Epoch 90/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5581 - acc: 0.7409\n",
      "Epoch 91/500\n",
      "521/521 [==============================] - 1s 993us/step - loss: 0.5656 - acc: 0.7543\n",
      "Epoch 92/500\n",
      "521/521 [==============================] - 0s 955us/step - loss: 0.5591 - acc: 0.7179\n",
      "Epoch 93/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.5470 - acc: 0.7121\n",
      "Epoch 94/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.5544 - acc: 0.6833\n",
      "Epoch 95/500\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.5408 - acc: 0.7332\n",
      "Epoch 96/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.5478 - acc: 0.7543\n",
      "Epoch 97/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5441 - acc: 0.7582\n",
      "Epoch 98/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.5433 - acc: 0.7313\n",
      "Epoch 99/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5346 - acc: 0.7390\n",
      "Epoch 100/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5225 - acc: 0.7466\n",
      "Epoch 101/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.5161 - acc: 0.7716\n",
      "Epoch 102/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5260 - acc: 0.7869\n",
      "Epoch 103/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.5126 - acc: 0.7658\n",
      "Epoch 104/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.5115 - acc: 0.7543\n",
      "Epoch 105/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.5118 - acc: 0.7678\n",
      "Epoch 106/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.4923 - acc: 0.8177\n",
      "Epoch 107/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.5071 - acc: 0.7927\n",
      "Epoch 108/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.4743 - acc: 0.8177\n",
      "Epoch 109/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.4867 - acc: 0.8004\n",
      "Epoch 110/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.4809 - acc: 0.7812\n",
      "Epoch 111/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.4746 - acc: 0.8023\n",
      "Epoch 112/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.4518 - acc: 0.8464\n",
      "Epoch 113/500\n",
      "521/521 [==============================] - 1s 987us/step - loss: 0.4545 - acc: 0.8042\n",
      "Epoch 114/500\n",
      "521/521 [==============================] - 0s 922us/step - loss: 0.4491 - acc: 0.8215\n",
      "Epoch 115/500\n",
      "521/521 [==============================] - 0s 951us/step - loss: 0.4557 - acc: 0.8234\n",
      "Epoch 116/500\n",
      "521/521 [==============================] - 0s 866us/step - loss: 0.4413 - acc: 0.8157\n",
      "Epoch 117/500\n",
      "521/521 [==============================] - 0s 903us/step - loss: 0.4449 - acc: 0.8177\n",
      "Epoch 118/500\n",
      "521/521 [==============================] - 0s 892us/step - loss: 0.4276 - acc: 0.8292\n",
      "Epoch 119/500\n",
      "521/521 [==============================] - 0s 884us/step - loss: 0.4320 - acc: 0.8234\n",
      "Epoch 120/500\n",
      "521/521 [==============================] - 0s 903us/step - loss: 0.4114 - acc: 0.8369\n",
      "Epoch 121/500\n",
      "521/521 [==============================] - 0s 913us/step - loss: 0.4286 - acc: 0.8330\n",
      "Epoch 122/500\n",
      "521/521 [==============================] - 0s 879us/step - loss: 0.4152 - acc: 0.8330\n",
      "Epoch 123/500\n",
      "521/521 [==============================] - 0s 866us/step - loss: 0.4261 - acc: 0.8234\n",
      "Epoch 124/500\n",
      "521/521 [==============================] - 1s 978us/step - loss: 0.4092 - acc: 0.8407\n",
      "Epoch 125/500\n",
      "521/521 [==============================] - 0s 938us/step - loss: 0.3982 - acc: 0.8177\n",
      "Epoch 126/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.4030 - acc: 0.8426\n",
      "Epoch 127/500\n",
      "521/521 [==============================] - 0s 894us/step - loss: 0.4056 - acc: 0.8253\n",
      "Epoch 128/500\n",
      "521/521 [==============================] - 0s 899us/step - loss: 0.3902 - acc: 0.8369\n",
      "Epoch 129/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3904 - acc: 0.8234\n",
      "Epoch 130/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3608 - acc: 0.8714\n",
      "Epoch 131/500\n",
      "521/521 [==============================] - 1s 969us/step - loss: 0.3872 - acc: 0.8445\n",
      "Epoch 132/500\n",
      "521/521 [==============================] - 0s 958us/step - loss: 0.3798 - acc: 0.8484\n",
      "Epoch 133/500\n",
      "521/521 [==============================] - 0s 834us/step - loss: 0.3809 - acc: 0.8407\n",
      "Epoch 134/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.3790 - acc: 0.8503\n",
      "Epoch 135/500\n",
      "521/521 [==============================] - 0s 914us/step - loss: 0.3912 - acc: 0.8196\n",
      "Epoch 136/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3689 - acc: 0.8407\n",
      "Epoch 137/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3728 - acc: 0.8407\n",
      "Epoch 138/500\n",
      "521/521 [==============================] - 0s 934us/step - loss: 0.3701 - acc: 0.8464\n",
      "Epoch 139/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3616 - acc: 0.8407\n",
      "Epoch 140/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.3697 - acc: 0.8445\n",
      "Epoch 141/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3556 - acc: 0.8292\n",
      "Epoch 142/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.3773 - acc: 0.8330\n",
      "Epoch 143/500\n",
      "521/521 [==============================] - 0s 952us/step - loss: 0.3526 - acc: 0.8637\n",
      "Epoch 144/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.3546 - acc: 0.8560\n",
      "Epoch 145/500\n",
      "521/521 [==============================] - 0s 924us/step - loss: 0.3708 - acc: 0.8426\n",
      "Epoch 146/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3590 - acc: 0.8388\n",
      "Epoch 147/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.3669 - acc: 0.8388\n",
      "Epoch 148/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3673 - acc: 0.8560\n",
      "Epoch 149/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.3579 - acc: 0.8445\n",
      "Epoch 150/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.3461 - acc: 0.8464\n",
      "Epoch 151/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3416 - acc: 0.8484\n",
      "Epoch 152/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3620 - acc: 0.8503\n",
      "Epoch 153/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3405 - acc: 0.8541\n",
      "Epoch 154/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3548 - acc: 0.8464\n",
      "Epoch 155/500\n",
      "521/521 [==============================] - 0s 955us/step - loss: 0.3624 - acc: 0.8388\n",
      "Epoch 156/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.3339 - acc: 0.8618\n",
      "Epoch 157/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3472 - acc: 0.8695\n",
      "Epoch 158/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3441 - acc: 0.8695\n",
      "Epoch 159/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.3477 - acc: 0.8484\n",
      "Epoch 160/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.3493 - acc: 0.8503\n",
      "Epoch 161/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.3257 - acc: 0.8580\n",
      "Epoch 162/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.3386 - acc: 0.8560\n",
      "Epoch 163/500\n",
      "521/521 [==============================] - 0s 941us/step - loss: 0.3438 - acc: 0.8445\n",
      "Epoch 164/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3399 - acc: 0.8560\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521/521 [==============================] - 0s 926us/step - loss: 0.3307 - acc: 0.8656\n",
      "Epoch 166/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3266 - acc: 0.8695\n",
      "Epoch 167/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3206 - acc: 0.8695\n",
      "Epoch 168/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3306 - acc: 0.8695\n",
      "Epoch 169/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3313 - acc: 0.8580\n",
      "Epoch 170/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.3233 - acc: 0.8637\n",
      "Epoch 171/500\n",
      "521/521 [==============================] - 0s 941us/step - loss: 0.3268 - acc: 0.8714\n",
      "Epoch 172/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3278 - acc: 0.8580\n",
      "Epoch 173/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3219 - acc: 0.8560\n",
      "Epoch 174/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.3277 - acc: 0.8695\n",
      "Epoch 175/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.3427 - acc: 0.8637\n",
      "Epoch 176/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.3234 - acc: 0.8637\n",
      "Epoch 177/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2998 - acc: 0.8733\n",
      "Epoch 178/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3346 - acc: 0.8637\n",
      "Epoch 179/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3098 - acc: 0.8656\n",
      "Epoch 180/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.3067 - acc: 0.8676\n",
      "Epoch 181/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3289 - acc: 0.8656\n",
      "Epoch 182/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.3109 - acc: 0.8791\n",
      "Epoch 183/500\n",
      "521/521 [==============================] - 0s 945us/step - loss: 0.3117 - acc: 0.8695\n",
      "Epoch 184/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3224 - acc: 0.8618\n",
      "Epoch 185/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.3171 - acc: 0.8714\n",
      "Epoch 186/500\n",
      "521/521 [==============================] - 0s 955us/step - loss: 0.3242 - acc: 0.8541\n",
      "Epoch 187/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.3174 - acc: 0.8522\n",
      "Epoch 188/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3109 - acc: 0.8714\n",
      "Epoch 189/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3036 - acc: 0.8829\n",
      "Epoch 190/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.3158 - acc: 0.8656\n",
      "Epoch 191/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.3114 - acc: 0.8656\n",
      "Epoch 192/500\n",
      "521/521 [==============================] - 1s 984us/step - loss: 0.3111 - acc: 0.8676\n",
      "Epoch 193/500\n",
      "521/521 [==============================] - 0s 950us/step - loss: 0.3050 - acc: 0.8810\n",
      "Epoch 194/500\n",
      "521/521 [==============================] - 0s 941us/step - loss: 0.3118 - acc: 0.8522\n",
      "Epoch 195/500\n",
      "521/521 [==============================] - 0s 927us/step - loss: 0.2887 - acc: 0.8695\n",
      "Epoch 196/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2884 - acc: 0.8695\n",
      "Epoch 197/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2902 - acc: 0.8887\n",
      "Epoch 198/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.3175 - acc: 0.8503\n",
      "Epoch 199/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2972 - acc: 0.8772\n",
      "Epoch 200/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2923 - acc: 0.8733\n",
      "Epoch 201/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.3225 - acc: 0.8695\n",
      "Epoch 202/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.2903 - acc: 0.8714\n",
      "Epoch 203/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.3058 - acc: 0.8695\n",
      "Epoch 204/500\n",
      "521/521 [==============================] - 0s 883us/step - loss: 0.2927 - acc: 0.8848\n",
      "Epoch 205/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2958 - acc: 0.8810\n",
      "Epoch 206/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2974 - acc: 0.8772\n",
      "Epoch 207/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2770 - acc: 0.8810\n",
      "Epoch 208/500\n",
      "521/521 [==============================] - 0s 941us/step - loss: 0.2939 - acc: 0.8733\n",
      "Epoch 209/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2801 - acc: 0.8772\n",
      "Epoch 210/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2882 - acc: 0.8810\n",
      "Epoch 211/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2777 - acc: 0.8733\n",
      "Epoch 212/500\n",
      "521/521 [==============================] - 1s 969us/step - loss: 0.2981 - acc: 0.8714\n",
      "Epoch 213/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2892 - acc: 0.8733\n",
      "Epoch 214/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2904 - acc: 0.8810\n",
      "Epoch 215/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2924 - acc: 0.8733\n",
      "Epoch 216/500\n",
      "521/521 [==============================] - 0s 932us/step - loss: 0.2876 - acc: 0.8752\n",
      "Epoch 217/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2856 - acc: 0.8810\n",
      "Epoch 218/500\n",
      "521/521 [==============================] - 0s 890us/step - loss: 0.2925 - acc: 0.8695\n",
      "Epoch 219/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2656 - acc: 0.8791\n",
      "Epoch 220/500\n",
      "521/521 [==============================] - 0s 932us/step - loss: 0.2793 - acc: 0.8752\n",
      "Epoch 221/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.2890 - acc: 0.8733\n",
      "Epoch 222/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2802 - acc: 0.8772\n",
      "Epoch 223/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2839 - acc: 0.8695\n",
      "Epoch 224/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2722 - acc: 0.8848\n",
      "Epoch 225/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2672 - acc: 0.8887\n",
      "Epoch 226/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2741 - acc: 0.8906\n",
      "Epoch 227/500\n",
      "521/521 [==============================] - 0s 919us/step - loss: 0.2644 - acc: 0.8810\n",
      "Epoch 228/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2877 - acc: 0.8714\n",
      "Epoch 229/500\n",
      "521/521 [==============================] - 0s 900us/step - loss: 0.2878 - acc: 0.8676\n",
      "Epoch 230/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2803 - acc: 0.8733\n",
      "Epoch 231/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2859 - acc: 0.8752\n",
      "Epoch 232/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2768 - acc: 0.8791\n",
      "Epoch 233/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2819 - acc: 0.8637\n",
      "Epoch 234/500\n",
      "521/521 [==============================] - 0s 960us/step - loss: 0.2833 - acc: 0.8791\n",
      "Epoch 235/500\n",
      "521/521 [==============================] - 0s 873us/step - loss: 0.2826 - acc: 0.8848\n",
      "Epoch 236/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2790 - acc: 0.8752\n",
      "Epoch 237/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2861 - acc: 0.8733\n",
      "Epoch 238/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2670 - acc: 0.8887\n",
      "Epoch 239/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2687 - acc: 0.8944\n",
      "Epoch 240/500\n",
      "521/521 [==============================] - 0s 883us/step - loss: 0.2656 - acc: 0.8887\n",
      "Epoch 241/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2681 - acc: 0.8791\n",
      "Epoch 242/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2743 - acc: 0.8829\n",
      "Epoch 243/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2839 - acc: 0.8906\n",
      "Epoch 244/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2850 - acc: 0.8772\n",
      "Epoch 245/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.2626 - acc: 0.8848\n",
      "Epoch 246/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2504 - acc: 0.8887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/500\n",
      "521/521 [==============================] - 0s 883us/step - loss: 0.2673 - acc: 0.8848\n",
      "Epoch 248/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2793 - acc: 0.8829\n",
      "Epoch 249/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2700 - acc: 0.8676\n",
      "Epoch 250/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2851 - acc: 0.8791\n",
      "Epoch 251/500\n",
      "521/521 [==============================] - 0s 945us/step - loss: 0.2576 - acc: 0.9079\n",
      "Epoch 252/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2553 - acc: 0.8983\n",
      "Epoch 253/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2676 - acc: 0.8887\n",
      "Epoch 254/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2548 - acc: 0.8906\n",
      "Epoch 255/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2653 - acc: 0.8925\n",
      "Epoch 256/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2502 - acc: 0.8925\n",
      "Epoch 257/500\n",
      "521/521 [==============================] - 0s 936us/step - loss: 0.2660 - acc: 0.8887\n",
      "Epoch 258/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2591 - acc: 0.8868\n",
      "Epoch 259/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2525 - acc: 0.8944\n",
      "Epoch 260/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2561 - acc: 0.8925\n",
      "Epoch 261/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.2561 - acc: 0.8944\n",
      "Epoch 262/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2666 - acc: 0.9002\n",
      "Epoch 263/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2468 - acc: 0.9117\n",
      "Epoch 264/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2448 - acc: 0.9002\n",
      "Epoch 265/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2510 - acc: 0.8925\n",
      "Epoch 266/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2596 - acc: 0.8868\n",
      "Epoch 267/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.2763 - acc: 0.8810\n",
      "Epoch 268/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2511 - acc: 0.8944\n",
      "Epoch 269/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.2511 - acc: 0.8983\n",
      "Epoch 270/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2493 - acc: 0.8906\n",
      "Epoch 271/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2703 - acc: 0.8695\n",
      "Epoch 272/500\n",
      "521/521 [==============================] - 0s 921us/step - loss: 0.2587 - acc: 0.8791\n",
      "Epoch 273/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2548 - acc: 0.8983\n",
      "Epoch 274/500\n",
      "521/521 [==============================] - 0s 950us/step - loss: 0.2494 - acc: 0.9021\n",
      "Epoch 275/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2399 - acc: 0.8944\n",
      "Epoch 276/500\n",
      "521/521 [==============================] - 0s 931us/step - loss: 0.2545 - acc: 0.8868\n",
      "Epoch 277/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.2500 - acc: 0.8829\n",
      "Epoch 278/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2532 - acc: 0.8983\n",
      "Epoch 279/500\n",
      "521/521 [==============================] - 0s 893us/step - loss: 0.2586 - acc: 0.8906\n",
      "Epoch 280/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.2408 - acc: 0.8925\n",
      "Epoch 281/500\n",
      "521/521 [==============================] - 0s 878us/step - loss: 0.2492 - acc: 0.8887\n",
      "Epoch 282/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.2527 - acc: 0.8848\n",
      "Epoch 283/500\n",
      "521/521 [==============================] - 0s 924us/step - loss: 0.2475 - acc: 0.8964\n",
      "Epoch 284/500\n",
      "521/521 [==============================] - 0s 820us/step - loss: 0.2644 - acc: 0.8791\n",
      "Epoch 285/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.2487 - acc: 0.9002\n",
      "Epoch 286/500\n",
      "521/521 [==============================] - 0s 831us/step - loss: 0.2511 - acc: 0.9021\n",
      "Epoch 287/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.2427 - acc: 0.9002\n",
      "Epoch 288/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.2521 - acc: 0.8964\n",
      "Epoch 289/500\n",
      "521/521 [==============================] - 0s 841us/step - loss: 0.2504 - acc: 0.8887\n",
      "Epoch 290/500\n",
      "521/521 [==============================] - 0s 902us/step - loss: 0.2356 - acc: 0.9040\n",
      "Epoch 291/500\n",
      "521/521 [==============================] - 0s 865us/step - loss: 0.2563 - acc: 0.8983\n",
      "Epoch 292/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.2486 - acc: 0.8925\n",
      "Epoch 293/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.2473 - acc: 0.8944\n",
      "Epoch 294/500\n",
      "521/521 [==============================] - 0s 826us/step - loss: 0.2412 - acc: 0.8983\n",
      "Epoch 295/500\n",
      "521/521 [==============================] - 0s 851us/step - loss: 0.2405 - acc: 0.8964\n",
      "Epoch 296/500\n",
      "521/521 [==============================] - 0s 814us/step - loss: 0.2475 - acc: 0.8925\n",
      "Epoch 297/500\n",
      "521/521 [==============================] - 0s 848us/step - loss: 0.2415 - acc: 0.8983\n",
      "Epoch 298/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.2543 - acc: 0.8944\n",
      "Epoch 299/500\n",
      "521/521 [==============================] - 0s 846us/step - loss: 0.2314 - acc: 0.8944\n",
      "Epoch 300/500\n",
      "521/521 [==============================] - 0s 900us/step - loss: 0.2656 - acc: 0.8829\n",
      "Epoch 301/500\n",
      "521/521 [==============================] - 0s 831us/step - loss: 0.2631 - acc: 0.8829\n",
      "Epoch 302/500\n",
      "521/521 [==============================] - 0s 820us/step - loss: 0.2620 - acc: 0.8944\n",
      "Epoch 303/500\n",
      "521/521 [==============================] - 0s 848us/step - loss: 0.2455 - acc: 0.9021\n",
      "Epoch 304/500\n",
      "521/521 [==============================] - 0s 879us/step - loss: 0.2441 - acc: 0.8944\n",
      "Epoch 305/500\n",
      "521/521 [==============================] - 0s 823us/step - loss: 0.2436 - acc: 0.9002\n",
      "Epoch 306/500\n",
      "521/521 [==============================] - 0s 835us/step - loss: 0.2391 - acc: 0.8906\n",
      "Epoch 307/500\n",
      "521/521 [==============================] - 0s 843us/step - loss: 0.2508 - acc: 0.8944\n",
      "Epoch 308/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2298 - acc: 0.9040\n",
      "Epoch 309/500\n",
      "521/521 [==============================] - 0s 951us/step - loss: 0.2449 - acc: 0.9060\n",
      "Epoch 310/500\n",
      "521/521 [==============================] - 0s 891us/step - loss: 0.2489 - acc: 0.8925\n",
      "Epoch 311/500\n",
      "521/521 [==============================] - 0s 886us/step - loss: 0.2354 - acc: 0.9021\n",
      "Epoch 312/500\n",
      "521/521 [==============================] - 0s 890us/step - loss: 0.2280 - acc: 0.8944\n",
      "Epoch 313/500\n",
      "521/521 [==============================] - 0s 926us/step - loss: 0.2275 - acc: 0.9213\n",
      "Epoch 314/500\n",
      "521/521 [==============================] - 0s 888us/step - loss: 0.2465 - acc: 0.9060\n",
      "Epoch 315/500\n",
      "521/521 [==============================] - 0s 917us/step - loss: 0.2449 - acc: 0.9021\n",
      "Epoch 316/500\n",
      "521/521 [==============================] - 0s 912us/step - loss: 0.2338 - acc: 0.8925\n",
      "Epoch 317/500\n",
      "521/521 [==============================] - 0s 909us/step - loss: 0.2305 - acc: 0.9021\n",
      "Epoch 318/500\n",
      "521/521 [==============================] - 0s 897us/step - loss: 0.2284 - acc: 0.9040\n",
      "Epoch 319/500\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.2394 - acc: 0.9060\n",
      "Epoch 320/500\n",
      "521/521 [==============================] - 1s 981us/step - loss: 0.2369 - acc: 0.8983\n",
      "Epoch 321/500\n",
      "521/521 [==============================] - 0s 842us/step - loss: 0.2542 - acc: 0.8810\n",
      "Epoch 322/500\n",
      "521/521 [==============================] - 0s 832us/step - loss: 0.2369 - acc: 0.8964\n",
      "Epoch 323/500\n",
      "521/521 [==============================] - 0s 845us/step - loss: 0.2197 - acc: 0.9021\n",
      "Epoch 324/500\n",
      "521/521 [==============================] - 0s 958us/step - loss: 0.2432 - acc: 0.8944\n",
      "Epoch 325/500\n",
      "521/521 [==============================] - 0s 866us/step - loss: 0.2226 - acc: 0.9040\n",
      "Epoch 326/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.2182 - acc: 0.9117\n",
      "Epoch 327/500\n",
      "521/521 [==============================] - 1s 964us/step - loss: 0.2298 - acc: 0.9060\n",
      "Epoch 328/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.2311 - acc: 0.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "521/521 [==============================] - 0s 835us/step - loss: 0.2166 - acc: 0.9079\n",
      "Epoch 330/500\n",
      "521/521 [==============================] - 0s 916us/step - loss: 0.2283 - acc: 0.9021\n",
      "Epoch 331/500\n",
      "521/521 [==============================] - 0s 818us/step - loss: 0.2238 - acc: 0.9040\n",
      "Epoch 332/500\n",
      "521/521 [==============================] - 0s 830us/step - loss: 0.2358 - acc: 0.9079\n",
      "Epoch 333/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.2366 - acc: 0.9098\n",
      "Epoch 334/500\n",
      "521/521 [==============================] - 0s 848us/step - loss: 0.2148 - acc: 0.9098\n",
      "Epoch 335/500\n",
      "521/521 [==============================] - 0s 877us/step - loss: 0.2347 - acc: 0.8964\n",
      "Epoch 336/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.2281 - acc: 0.8983\n",
      "Epoch 337/500\n",
      "521/521 [==============================] - 0s 788us/step - loss: 0.2254 - acc: 0.8983\n",
      "Epoch 338/500\n",
      "521/521 [==============================] - 0s 820us/step - loss: 0.2047 - acc: 0.9213\n",
      "Epoch 339/500\n",
      "521/521 [==============================] - 0s 863us/step - loss: 0.2185 - acc: 0.9136\n",
      "Epoch 340/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2250 - acc: 0.9136\n",
      "Epoch 341/500\n",
      "521/521 [==============================] - 0s 818us/step - loss: 0.2291 - acc: 0.9040\n",
      "Epoch 342/500\n",
      "521/521 [==============================] - 0s 828us/step - loss: 0.2275 - acc: 0.9060\n",
      "Epoch 343/500\n",
      "521/521 [==============================] - 0s 803us/step - loss: 0.2120 - acc: 0.9021\n",
      "Epoch 344/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2113 - acc: 0.8983\n",
      "Epoch 345/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2408 - acc: 0.9136\n",
      "Epoch 346/500\n",
      "521/521 [==============================] - 0s 833us/step - loss: 0.2227 - acc: 0.9175\n",
      "Epoch 347/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2053 - acc: 0.9213\n",
      "Epoch 348/500\n",
      "521/521 [==============================] - 0s 812us/step - loss: 0.2244 - acc: 0.9098\n",
      "Epoch 349/500\n",
      "521/521 [==============================] - 0s 865us/step - loss: 0.1980 - acc: 0.9098\n",
      "Epoch 350/500\n",
      "521/521 [==============================] - 0s 876us/step - loss: 0.2176 - acc: 0.9155\n",
      "Epoch 351/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.2147 - acc: 0.9060\n",
      "Epoch 352/500\n",
      "521/521 [==============================] - 0s 803us/step - loss: 0.2075 - acc: 0.9136\n",
      "Epoch 353/500\n",
      "521/521 [==============================] - 0s 798us/step - loss: 0.2105 - acc: 0.9136\n",
      "Epoch 354/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.2345 - acc: 0.9117\n",
      "Epoch 355/500\n",
      "521/521 [==============================] - 0s 828us/step - loss: 0.2152 - acc: 0.9155\n",
      "Epoch 356/500\n",
      "521/521 [==============================] - 0s 847us/step - loss: 0.2053 - acc: 0.9194\n",
      "Epoch 357/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.2082 - acc: 0.9155\n",
      "Epoch 358/500\n",
      "521/521 [==============================] - 0s 831us/step - loss: 0.2074 - acc: 0.9040\n",
      "Epoch 359/500\n",
      "521/521 [==============================] - 0s 811us/step - loss: 0.2329 - acc: 0.9002\n",
      "Epoch 360/500\n",
      "521/521 [==============================] - 0s 803us/step - loss: 0.2182 - acc: 0.9098\n",
      "Epoch 361/500\n",
      "521/521 [==============================] - 0s 815us/step - loss: 0.2131 - acc: 0.9079\n",
      "Epoch 362/500\n",
      "521/521 [==============================] - 0s 815us/step - loss: 0.2237 - acc: 0.9040\n",
      "Epoch 363/500\n",
      "521/521 [==============================] - 0s 816us/step - loss: 0.2020 - acc: 0.9117\n",
      "Epoch 364/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.2161 - acc: 0.9098\n",
      "Epoch 365/500\n",
      "521/521 [==============================] - 0s 859us/step - loss: 0.2063 - acc: 0.9175\n",
      "Epoch 366/500\n",
      "521/521 [==============================] - 0s 863us/step - loss: 0.2160 - acc: 0.9060\n",
      "Epoch 367/500\n",
      "521/521 [==============================] - 0s 831us/step - loss: 0.2198 - acc: 0.9021\n",
      "Epoch 368/500\n",
      "521/521 [==============================] - 0s 832us/step - loss: 0.2046 - acc: 0.9136\n",
      "Epoch 369/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.2154 - acc: 0.9213\n",
      "Epoch 370/500\n",
      "521/521 [==============================] - 0s 870us/step - loss: 0.2087 - acc: 0.9079\n",
      "Epoch 371/500\n",
      "521/521 [==============================] - 0s 842us/step - loss: 0.2028 - acc: 0.9213\n",
      "Epoch 372/500\n",
      "521/521 [==============================] - 0s 837us/step - loss: 0.2104 - acc: 0.9155\n",
      "Epoch 373/500\n",
      "521/521 [==============================] - 0s 816us/step - loss: 0.2112 - acc: 0.9021\n",
      "Epoch 374/500\n",
      "521/521 [==============================] - 0s 933us/step - loss: 0.1971 - acc: 0.9136\n",
      "Epoch 375/500\n",
      "521/521 [==============================] - 0s 880us/step - loss: 0.2016 - acc: 0.9136\n",
      "Epoch 376/500\n",
      "521/521 [==============================] - 0s 824us/step - loss: 0.1960 - acc: 0.9079\n",
      "Epoch 377/500\n",
      "521/521 [==============================] - 0s 922us/step - loss: 0.2118 - acc: 0.9060\n",
      "Epoch 378/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.2064 - acc: 0.9175\n",
      "Epoch 379/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.2033 - acc: 0.9040\n",
      "Epoch 380/500\n",
      "521/521 [==============================] - 0s 828us/step - loss: 0.2191 - acc: 0.9175\n",
      "Epoch 381/500\n",
      "521/521 [==============================] - 0s 830us/step - loss: 0.1980 - acc: 0.9079\n",
      "Epoch 382/500\n",
      "521/521 [==============================] - 0s 837us/step - loss: 0.2135 - acc: 0.9079\n",
      "Epoch 383/500\n",
      "521/521 [==============================] - 0s 848us/step - loss: 0.1892 - acc: 0.9232\n",
      "Epoch 384/500\n",
      "521/521 [==============================] - 0s 839us/step - loss: 0.2041 - acc: 0.9021\n",
      "Epoch 385/500\n",
      "521/521 [==============================] - 0s 842us/step - loss: 0.2060 - acc: 0.9155\n",
      "Epoch 386/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.2079 - acc: 0.9040\n",
      "Epoch 387/500\n",
      "521/521 [==============================] - 0s 840us/step - loss: 0.1961 - acc: 0.9213\n",
      "Epoch 388/500\n",
      "521/521 [==============================] - 0s 809us/step - loss: 0.1926 - acc: 0.9175\n",
      "Epoch 389/500\n",
      "521/521 [==============================] - 0s 814us/step - loss: 0.1950 - acc: 0.9098\n",
      "Epoch 390/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.1795 - acc: 0.9213\n",
      "Epoch 391/500\n",
      "521/521 [==============================] - 0s 911us/step - loss: 0.1881 - acc: 0.9117\n",
      "Epoch 392/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1771 - acc: 0.9251\n",
      "Epoch 393/500\n",
      "521/521 [==============================] - 0s 880us/step - loss: 0.1867 - acc: 0.9213\n",
      "Epoch 394/500\n",
      "521/521 [==============================] - 0s 892us/step - loss: 0.1968 - acc: 0.9136\n",
      "Epoch 395/500\n",
      "521/521 [==============================] - 0s 832us/step - loss: 0.1938 - acc: 0.9271\n",
      "Epoch 396/500\n",
      "521/521 [==============================] - 0s 799us/step - loss: 0.1913 - acc: 0.9194\n",
      "Epoch 397/500\n",
      "521/521 [==============================] - 0s 797us/step - loss: 0.2014 - acc: 0.9194\n",
      "Epoch 398/500\n",
      "521/521 [==============================] - 0s 843us/step - loss: 0.2023 - acc: 0.9136\n",
      "Epoch 399/500\n",
      "521/521 [==============================] - 0s 816us/step - loss: 0.1994 - acc: 0.9098\n",
      "Epoch 400/500\n",
      "521/521 [==============================] - 0s 842us/step - loss: 0.1764 - acc: 0.9194\n",
      "Epoch 401/500\n",
      "521/521 [==============================] - 0s 909us/step - loss: 0.1871 - acc: 0.9117\n",
      "Epoch 402/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.1935 - acc: 0.9213\n",
      "Epoch 403/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1956 - acc: 0.9290\n",
      "Epoch 404/500\n",
      "521/521 [==============================] - 0s 826us/step - loss: 0.2052 - acc: 0.9098\n",
      "Epoch 405/500\n",
      "521/521 [==============================] - 0s 846us/step - loss: 0.1988 - acc: 0.9021\n",
      "Epoch 406/500\n",
      "521/521 [==============================] - 0s 846us/step - loss: 0.1893 - acc: 0.9194\n",
      "Epoch 407/500\n",
      "521/521 [==============================] - 0s 843us/step - loss: 0.1890 - acc: 0.9175\n",
      "Epoch 408/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1906 - acc: 0.9194\n",
      "Epoch 409/500\n",
      "521/521 [==============================] - 0s 841us/step - loss: 0.1793 - acc: 0.9194\n",
      "Epoch 410/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.2005 - acc: 0.9155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/500\n",
      "521/521 [==============================] - 0s 898us/step - loss: 0.1846 - acc: 0.9309\n",
      "Epoch 412/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1740 - acc: 0.9251\n",
      "Epoch 413/500\n",
      "521/521 [==============================] - 0s 857us/step - loss: 0.1704 - acc: 0.9213\n",
      "Epoch 414/500\n",
      "521/521 [==============================] - 0s 894us/step - loss: 0.1824 - acc: 0.9232\n",
      "Epoch 415/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1800 - acc: 0.9232\n",
      "Epoch 416/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.1906 - acc: 0.9251\n",
      "Epoch 417/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1631 - acc: 0.9482\n",
      "Epoch 418/500\n",
      "521/521 [==============================] - 0s 861us/step - loss: 0.1641 - acc: 0.9271\n",
      "Epoch 419/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.1682 - acc: 0.9328\n",
      "Epoch 420/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.1722 - acc: 0.9309\n",
      "Epoch 421/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1668 - acc: 0.9290\n",
      "Epoch 422/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.1858 - acc: 0.9194\n",
      "Epoch 423/500\n",
      "521/521 [==============================] - 0s 841us/step - loss: 0.1937 - acc: 0.9251\n",
      "Epoch 424/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.1616 - acc: 0.9290\n",
      "Epoch 425/500\n",
      "521/521 [==============================] - 0s 869us/step - loss: 0.1694 - acc: 0.9290\n",
      "Epoch 426/500\n",
      "521/521 [==============================] - 0s 803us/step - loss: 0.1993 - acc: 0.9194\n",
      "Epoch 427/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.1609 - acc: 0.9290\n",
      "Epoch 428/500\n",
      "521/521 [==============================] - 0s 889us/step - loss: 0.1683 - acc: 0.9213\n",
      "Epoch 429/500\n",
      "521/521 [==============================] - 0s 818us/step - loss: 0.1593 - acc: 0.9290\n",
      "Epoch 430/500\n",
      "521/521 [==============================] - 0s 898us/step - loss: 0.1658 - acc: 0.9309\n",
      "Epoch 431/500\n",
      "521/521 [==============================] - 0s 828us/step - loss: 0.1657 - acc: 0.9290\n",
      "Epoch 432/500\n",
      "521/521 [==============================] - 0s 831us/step - loss: 0.1747 - acc: 0.9194\n",
      "Epoch 433/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1565 - acc: 0.9386\n",
      "Epoch 434/500\n",
      "521/521 [==============================] - 0s 913us/step - loss: 0.1635 - acc: 0.9251\n",
      "Epoch 435/500\n",
      "521/521 [==============================] - 0s 886us/step - loss: 0.1757 - acc: 0.9136\n",
      "Epoch 436/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1763 - acc: 0.9290\n",
      "Epoch 437/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.1948 - acc: 0.9194\n",
      "Epoch 438/500\n",
      "521/521 [==============================] - 0s 852us/step - loss: 0.1598 - acc: 0.9309\n",
      "Epoch 439/500\n",
      "521/521 [==============================] - 0s 826us/step - loss: 0.1704 - acc: 0.9194\n",
      "Epoch 440/500\n",
      "521/521 [==============================] - 0s 820us/step - loss: 0.1556 - acc: 0.9347\n",
      "Epoch 441/500\n",
      "521/521 [==============================] - 0s 906us/step - loss: 0.1567 - acc: 0.9405\n",
      "Epoch 442/500\n",
      "521/521 [==============================] - 0s 843us/step - loss: 0.1913 - acc: 0.9155\n",
      "Epoch 443/500\n",
      "521/521 [==============================] - 0s 837us/step - loss: 0.1462 - acc: 0.9482\n",
      "Epoch 444/500\n",
      "521/521 [==============================] - 0s 877us/step - loss: 0.1586 - acc: 0.9328\n",
      "Epoch 445/500\n",
      "521/521 [==============================] - 0s 812us/step - loss: 0.1706 - acc: 0.9271\n",
      "Epoch 446/500\n",
      "521/521 [==============================] - 0s 846us/step - loss: 0.1624 - acc: 0.9328\n",
      "Epoch 447/500\n",
      "521/521 [==============================] - 0s 815us/step - loss: 0.1725 - acc: 0.9213\n",
      "Epoch 448/500\n",
      "521/521 [==============================] - 0s 846us/step - loss: 0.1581 - acc: 0.9463\n",
      "Epoch 449/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1693 - acc: 0.9251\n",
      "Epoch 450/500\n",
      "521/521 [==============================] - 0s 807us/step - loss: 0.1576 - acc: 0.9443\n",
      "Epoch 451/500\n",
      "521/521 [==============================] - 0s 853us/step - loss: 0.1531 - acc: 0.9328\n",
      "Epoch 452/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1629 - acc: 0.9328\n",
      "Epoch 453/500\n",
      "521/521 [==============================] - 0s 821us/step - loss: 0.1464 - acc: 0.9290\n",
      "Epoch 454/500\n",
      "521/521 [==============================] - 1s 1ms/step - loss: 0.1722 - acc: 0.9290\n",
      "Epoch 455/500\n",
      "521/521 [==============================] - 0s 818us/step - loss: 0.1629 - acc: 0.9367\n",
      "Epoch 456/500\n",
      "521/521 [==============================] - 0s 803us/step - loss: 0.1733 - acc: 0.9290\n",
      "Epoch 457/500\n",
      "521/521 [==============================] - 0s 807us/step - loss: 0.1424 - acc: 0.9443\n",
      "Epoch 458/500\n",
      "521/521 [==============================] - 0s 882us/step - loss: 0.1582 - acc: 0.9309\n",
      "Epoch 459/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.1441 - acc: 0.9501\n",
      "Epoch 460/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.1518 - acc: 0.9424\n",
      "Epoch 461/500\n",
      "521/521 [==============================] - 0s 809us/step - loss: 0.1706 - acc: 0.9328\n",
      "Epoch 462/500\n",
      "521/521 [==============================] - 0s 834us/step - loss: 0.1408 - acc: 0.9482\n",
      "Epoch 463/500\n",
      "521/521 [==============================] - 0s 907us/step - loss: 0.1681 - acc: 0.9328\n",
      "Epoch 464/500\n",
      "521/521 [==============================] - 0s 836us/step - loss: 0.1445 - acc: 0.9309\n",
      "Epoch 465/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1682 - acc: 0.9328\n",
      "Epoch 466/500\n",
      "521/521 [==============================] - 0s 812us/step - loss: 0.1578 - acc: 0.9347\n",
      "Epoch 467/500\n",
      "521/521 [==============================] - 0s 880us/step - loss: 0.1723 - acc: 0.9367\n",
      "Epoch 468/500\n",
      "521/521 [==============================] - 0s 840us/step - loss: 0.1763 - acc: 0.9213\n",
      "Epoch 469/500\n",
      "521/521 [==============================] - 0s 823us/step - loss: 0.1392 - acc: 0.9482\n",
      "Epoch 470/500\n",
      "521/521 [==============================] - 0s 905us/step - loss: 0.1574 - acc: 0.9251\n",
      "Epoch 471/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.1702 - acc: 0.9213\n",
      "Epoch 472/500\n",
      "521/521 [==============================] - 0s 840us/step - loss: 0.1499 - acc: 0.9367\n",
      "Epoch 473/500\n",
      "521/521 [==============================] - 0s 828us/step - loss: 0.1497 - acc: 0.9405\n",
      "Epoch 474/500\n",
      "521/521 [==============================] - 0s 822us/step - loss: 0.1567 - acc: 0.9443\n",
      "Epoch 475/500\n",
      "521/521 [==============================] - 0s 812us/step - loss: 0.1358 - acc: 0.9482\n",
      "Epoch 476/500\n",
      "521/521 [==============================] - 0s 884us/step - loss: 0.1694 - acc: 0.9386\n",
      "Epoch 477/500\n",
      "521/521 [==============================] - 0s 816us/step - loss: 0.1656 - acc: 0.9347\n",
      "Epoch 478/500\n",
      "521/521 [==============================] - 0s 802us/step - loss: 0.1364 - acc: 0.9443\n",
      "Epoch 479/500\n",
      "521/521 [==============================] - 0s 898us/step - loss: 0.1648 - acc: 0.9309\n",
      "Epoch 480/500\n",
      "521/521 [==============================] - 0s 826us/step - loss: 0.1277 - acc: 0.9424\n",
      "Epoch 481/500\n",
      "521/521 [==============================] - 0s 904us/step - loss: 0.1436 - acc: 0.9424\n",
      "Epoch 482/500\n",
      "521/521 [==============================] - 0s 856us/step - loss: 0.1445 - acc: 0.9367\n",
      "Epoch 483/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1507 - acc: 0.9463\n",
      "Epoch 484/500\n",
      "521/521 [==============================] - 0s 857us/step - loss: 0.1413 - acc: 0.9367\n",
      "Epoch 485/500\n",
      "521/521 [==============================] - 0s 866us/step - loss: 0.1412 - acc: 0.9367\n",
      "Epoch 486/500\n",
      "521/521 [==============================] - 0s 807us/step - loss: 0.1356 - acc: 0.9386\n",
      "Epoch 487/500\n",
      "521/521 [==============================] - 0s 811us/step - loss: 0.1487 - acc: 0.9501\n",
      "Epoch 488/500\n",
      "521/521 [==============================] - 0s 806us/step - loss: 0.1442 - acc: 0.9405\n",
      "Epoch 489/500\n",
      "521/521 [==============================] - 0s 904us/step - loss: 0.1499 - acc: 0.9367\n",
      "Epoch 490/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1315 - acc: 0.9367\n",
      "Epoch 491/500\n",
      "521/521 [==============================] - 0s 816us/step - loss: 0.1347 - acc: 0.9463\n",
      "Epoch 492/500\n",
      "521/521 [==============================] - 0s 845us/step - loss: 0.1485 - acc: 0.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/500\n",
      "521/521 [==============================] - 0s 841us/step - loss: 0.1363 - acc: 0.9482\n",
      "Epoch 494/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1531 - acc: 0.9424\n",
      "Epoch 495/500\n",
      "521/521 [==============================] - 0s 863us/step - loss: 0.1308 - acc: 0.9520\n",
      "Epoch 496/500\n",
      "521/521 [==============================] - 0s 827us/step - loss: 0.1422 - acc: 0.9367\n",
      "Epoch 497/500\n",
      "521/521 [==============================] - 0s 817us/step - loss: 0.1288 - acc: 0.9424\n",
      "Epoch 498/500\n",
      "521/521 [==============================] - 0s 833us/step - loss: 0.1609 - acc: 0.9424\n",
      "Epoch 499/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1393 - acc: 0.9443\n",
      "Epoch 500/500\n",
      "521/521 [==============================] - 0s 813us/step - loss: 0.1439 - acc: 0.9501\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "epochs=500\n",
    "\n",
    "gf_or_note_input,gf_or_note_output=prepare_sequences_gf_or_note(DF,len(WordToNumber),WordToNumber)\n",
    "get_gf_input,get_gf_output=prepare_sequences_get_gf(DF,len(WordToNumber),WordToNumber,GfToNumber)\n",
    "get_note_input,get_note_output=prepare_sequences_get_note(DF,len(WordToNumber),WordToNumber,NoteToNumber)\n",
    "\n",
    "print('Sequences Prepared, creating models')\n",
    "\n",
    "gf_or_note=create_network_gf_or_note(gf_or_note_input,gf_or_note_output.shape[1])\n",
    "get_gf=create_network_get_gf(get_gf_input,get_gf_output.shape[1])\n",
    "get_note=create_network_get_note(get_note_input,get_note_output.shape[1])\n",
    "\n",
    "print('Models Created, training in progress')\n",
    "\n",
    "train_gf_or_note(gf_or_note,gf_or_note_input,gf_or_note_output,epochs)\n",
    "#train_get_gf(get_gf,get_gf_input,get_gf_output,epochs)\n",
    "#train_get_note(get_note,get_note_input,get_note_output,epochs)\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for get_gf\n",
    "index=gf_or_note_input.shape[0]\n",
    "result=[]\n",
    "actual=[]\n",
    "for i in range(index):\n",
    "    goingin=np.reshape(gf_or_note_input[i,:,:],(1,100,1))\n",
    "    shouldGoOut=gf_or_note_output[i,:]\n",
    "    weGet=gf_or_note.predict(goingin)\n",
    "    weGet=np.argmax(weGet)\n",
    "    result.append(weGet)\n",
    "    actual.append(np.argmax(shouldGoOut))\n",
    "actual=np.array(actual)\n",
    "result=np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actual)):\n",
    "    print(str(actual[i])+' '+str(result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we now test to see how the neural network is working:\n",
    "true=[]\n",
    "result=[]\n",
    "song=DF.iloc[1,2]\n",
    "for i in range(len(song)-100):\n",
    "    sequenceHere=song[i:i+100]\n",
    "    if 'gf' not in str(song[i+100]):\n",
    "        \n",
    "        transformSequenceHere=[WordToNumber[each] for each in sequenceHere]\n",
    "        \n",
    "        transformSequenceHere=np.reshape(transformSequenceHere,(1,100,1))\n",
    "        \n",
    "        transformSequenceHere=transformSequenceHere/len(vocab)\n",
    "        \n",
    "        weGet=get_note.predict(transformSequenceHere)\n",
    "        \n",
    "        weGet=np.argmax(weGet)\n",
    "        weGet=NumberToNote[weGet]\n",
    "        #print('We Get: '+str(weGet)+' when it is '+str(song[i+100]) )\n",
    "        true.append(song[i+100])\n",
    "        result.append(weGet)\n",
    "true=np.array(true)\n",
    "result=np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(true==result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for get_gf\n",
    "index=get_gf_input.shape[0]\n",
    "result=[]\n",
    "actual=[]\n",
    "for i in range(index):\n",
    "    goingin=np.reshape(get_gf_input[i,:,:],(1,100,1))\n",
    "    shouldGoOut=get_gf_output[i,:]\n",
    "    weGet=get_gf.predict(goingin)\n",
    "    weGet=np.argmax(weGet)\n",
    "    result.append(weGet)\n",
    "    actual.append(np.argmax(shouldGoOut))\n",
    "actual=np.array(actual)\n",
    "result=np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "3 3\n",
      "5 5\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "3 3\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actual)):\n",
    "    print(str(actual[i])+' '+str(result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for get_note\n",
    "index=get_note_input.shape[0]\n",
    "result=[]\n",
    "actual=[]\n",
    "for i in range(index):\n",
    "    goingin=np.reshape(get_note_input[i,:,:],(1,100,1))\n",
    "    shouldGoOut=get_note_output[i,:]\n",
    "    weGet=get_note.predict(goingin)\n",
    "    weGet=np.argmax(weGet)\n",
    "    result.append(weGet)\n",
    "    actual.append(np.argmax(shouldGoOut))\n",
    "actual=np.array(actual)\n",
    "result=np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 26\n",
      "33 33\n",
      "37 38\n",
      "42 42\n",
      "33 33\n",
      "28 28\n",
      "40 43\n",
      "1 1\n",
      "11 11\n",
      "25 25\n",
      "20 26\n",
      "28 28\n",
      "31 31\n",
      "37 33\n",
      "28 28\n",
      "23 23\n",
      "35 35\n",
      "4 4\n",
      "11 11\n",
      "21 21\n",
      "19 19\n",
      "26 26\n",
      "30 31\n",
      "33 33\n",
      "26 28\n",
      "23 23\n",
      "35 35\n",
      "3 4\n",
      "11 11\n",
      "21 21\n",
      "20 20\n",
      "28 28\n",
      "31 31\n",
      "33 33\n",
      "28 31\n",
      "23 23\n",
      "35 35\n",
      "4 4\n",
      "11 11\n",
      "21 21\n",
      "19 19\n",
      "26 26\n",
      "30 30\n",
      "33 33\n",
      "26 26\n",
      "23 23\n",
      "35 35\n",
      "8 4\n",
      "19 11\n",
      "25 21\n",
      "21 21\n",
      "30 31\n",
      "33 30\n",
      "37 37\n",
      "30 30\n",
      "26 26\n",
      "38 38\n",
      "9 9\n",
      "15 15\n",
      "27 27\n",
      "23 23\n",
      "31 31\n",
      "35 35\n",
      "39 39\n",
      "31 31\n",
      "28 28\n",
      "40 40\n",
      "11 11\n",
      "15 15\n",
      "29 29\n",
      "24 24\n",
      "33 33\n",
      "38 38\n",
      "41 41\n",
      "33 33\n",
      "30 30\n",
      "42 42\n",
      "12 12\n",
      "20 20\n",
      "33 33\n",
      "26 26\n",
      "35 33\n",
      "38 38\n",
      "45 45\n",
      "35 35\n",
      "31 31\n",
      "43 43\n",
      "11 1\n",
      "15 15\n",
      "29 29\n",
      "26 26\n",
      "33 33\n",
      "38 38\n",
      "41 41\n",
      "33 33\n",
      "30 30\n",
      "42 42\n",
      "12 12\n",
      "20 20\n",
      "30 30\n",
      "26 25\n",
      "35 33\n",
      "38 38\n",
      "42 42\n",
      "35 33\n",
      "31 31\n",
      "43 43\n",
      "14 14\n",
      "32 32\n",
      "21 21\n",
      "37 37\n",
      "28 28\n",
      "40 40\n",
      "44 44\n",
      "37 33\n",
      "33 28\n",
      "45 45\n",
      "15 15\n",
      "34 34\n",
      "21 21\n",
      "38 38\n",
      "30 30\n",
      "42 42\n",
      "46 46\n",
      "38 33\n",
      "35 35\n",
      "47 45\n",
      "17 17\n",
      "36 36\n",
      "21 21\n",
      "40 40\n",
      "31 31\n",
      "45 45\n",
      "48 48\n",
      "40 40\n",
      "37 35\n",
      "49 45\n",
      "19 17\n",
      "26 21\n",
      "40 38\n",
      "33 33\n",
      "42 42\n",
      "45 45\n",
      "52 52\n",
      "42 38\n",
      "38 37\n",
      "50 47\n",
      "10 10\n",
      "18 21\n",
      "37 38\n",
      "26 26\n",
      "38 38\n",
      "41 42\n",
      "49 49\n",
      "38 38\n",
      "35 35\n",
      "47 47\n",
      "11 4\n",
      "35 35\n",
      "19 19\n",
      "38 38\n",
      "26 33\n",
      "42 42\n",
      "47 47\n",
      "38 38\n",
      "33 38\n",
      "45 45\n",
      "11 11\n",
      "20 11\n",
      "30 30\n",
      "25 25\n",
      "33 33\n",
      "37 37\n",
      "42 42\n",
      "33 33\n",
      "28 28\n",
      "40 40\n",
      "4 4\n",
      "21 21\n",
      "11 11\n",
      "26 26\n",
      "19 19\n",
      "30 30\n",
      "33 33\n",
      "26 26\n",
      "23 23\n",
      "35 35\n",
      "4 4\n",
      "30 30\n",
      "11 11\n",
      "33 33\n",
      "20 20\n",
      "37 37\n",
      "42 42\n",
      "33 33\n",
      "28 28\n",
      "40 40\n",
      "4 4\n",
      "11 11\n",
      "21 21\n",
      "19 19\n",
      "26 26\n",
      "30 30\n",
      "33 33\n",
      "26 26\n",
      "23 23\n",
      "35 35\n",
      "4 4\n",
      "11 11\n",
      "30 30\n",
      "20 20\n",
      "33 33\n",
      "37 33\n",
      "42 42\n",
      "33 33\n",
      "28 28\n",
      "40 40\n",
      "4 4\n",
      "11 11\n",
      "26 26\n",
      "21 21\n",
      "31 31\n",
      "35 35\n",
      "38 38\n",
      "31 31\n",
      "30 30\n",
      "33 33\n",
      "4 4\n",
      "11 11\n",
      "26 26\n",
      "21 21\n",
      "31 31\n",
      "35 35\n",
      "38 38\n",
      "31 31\n",
      "30 30\n",
      "33 33\n",
      "4 4\n",
      "11 11\n",
      "26 26\n",
      "21 21\n",
      "31 31\n",
      "35 35\n",
      "38 38\n",
      "31 31\n",
      "30 30\n",
      "33 33\n",
      "4 4\n",
      "11 11\n",
      "26 26\n",
      "21 21\n",
      "31 31\n",
      "35 35\n",
      "38 38\n",
      "31 31\n",
      "30 30\n",
      "33 33\n",
      "4 4\n",
      "11 11\n",
      "15 15\n",
      "19 35\n",
      "21 35\n",
      "26 26\n",
      "16 16\n",
      "24 24\n",
      "13 13\n",
      "18 18\n",
      "26 26\n",
      "13 13\n",
      "19 13\n",
      "27 19\n",
      "13 13\n",
      "0 13\n",
      "26 19\n",
      "29 27\n",
      "2 2\n",
      "22 35\n",
      "30 30\n",
      "16 16\n",
      "22 22\n",
      "30 2\n",
      "57 57\n",
      "59 59\n",
      "58 58\n",
      "57 57\n",
      "54 54\n",
      "53 53\n",
      "51 51\n",
      "57 57\n",
      "53 53\n",
      "51 51\n",
      "47 47\n",
      "10 10\n",
      "16 16\n",
      "46 46\n",
      "23 23\n",
      "44 44\n",
      "51 51\n",
      "46 46\n",
      "44 44\n",
      "42 42\n",
      "16 16\n",
      "22 22\n",
      "41 41\n",
      "30 30\n",
      "39 39\n",
      "46 46\n",
      "41 41\n",
      "39 39\n",
      "35 35\n",
      "10 10\n",
      "16 16\n",
      "34 34\n",
      "23 23\n",
      "32 32\n",
      "39 39\n",
      "34 34\n",
      "32 32\n",
      "30 30\n",
      "5 5\n",
      "13 13\n",
      "29 29\n",
      "19 19\n",
      "27 27\n",
      "34 34\n",
      "29 29\n",
      "27 27\n",
      "25 25\n",
      "24 24\n",
      "22 22\n",
      "7 13\n",
      "18 18\n",
      "26 26\n",
      "29 29\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "21 18\n",
      "24 26\n",
      "7 7\n",
      "8 8\n",
      "7 7\n",
      "8 8\n",
      "6 6\n",
      "7 7\n",
      "7 7\n",
      "13 13\n",
      "18 18\n",
      "22 22\n",
      "25 25\n",
      "13 13\n",
      "18 13\n",
      "24 24\n",
      "27 27\n",
      "13 13\n",
      "18 26\n",
      "25 25\n",
      "29 29\n",
      "2 2\n",
      "22 22\n",
      "34 34\n",
      "10 10\n",
      "16 16\n",
      "23 23\n",
      "55 55\n",
      "59 59\n",
      "57 57\n",
      "55 55\n",
      "52 52\n",
      "14 14\n",
      "0 0\n",
      "51 51\n",
      "28 28\n",
      "49 49\n",
      "55 55\n",
      "51 51\n",
      "49 49\n",
      "47 47\n",
      "10 10\n",
      "16 16\n",
      "46 46\n",
      "23 23\n",
      "44 51\n",
      "51 51\n",
      "46 46\n",
      "44 44\n",
      "40 40\n",
      "14 14\n",
      "0 0\n",
      "39 39\n",
      "28 28\n",
      "37 37\n",
      "44 44\n",
      "39 39\n",
      "37 37\n",
      "35 35\n",
      "10 10\n",
      "16 16\n",
      "34 34\n",
      "23 23\n",
      "32 32\n",
      "39 39\n",
      "34 34\n",
      "32 32\n",
      "28 28\n",
      "27 27\n",
      "25 25\n",
      "32 32\n",
      "27 27\n",
      "25 25\n",
      "23 23\n",
      "22 22\n",
      "0 0\n",
      "10 10\n",
      "16 16\n",
      "23 23\n",
      "27 27\n",
      "7 7\n",
      "29 29\n",
      "13 13\n",
      "18 18\n",
      "22 22\n",
      "26 26\n",
      "13 13\n",
      "19 19\n",
      "22 22\n",
      "27 13\n",
      "13 13\n",
      "0 0\n",
      "26 26\n",
      "29 29\n",
      "2 2\n",
      "22 22\n",
      "30 30\n",
      "16 16\n",
      "22 22\n",
      "30 30\n",
      "57 57\n",
      "59 59\n",
      "58 58\n",
      "57 57\n",
      "54 54\n",
      "53 53\n",
      "51 51\n",
      "57 57\n",
      "53 53\n",
      "51 51\n",
      "47 47\n",
      "10 10\n",
      "16 16\n",
      "46 46\n",
      "23 23\n",
      "44 44\n",
      "51 51\n",
      "46 46\n",
      "44 44\n",
      "42 42\n",
      "16 16\n",
      "22 22\n",
      "41 41\n",
      "30 30\n",
      "39 39\n",
      "46 46\n",
      "41 41\n",
      "39 39\n",
      "35 35\n",
      "10 10\n",
      "16 16\n",
      "34 34\n",
      "23 23\n",
      "32 32\n",
      "39 39\n",
      "34 34\n",
      "32 32\n",
      "30 30\n",
      "5 5\n",
      "13 13\n",
      "29 29\n",
      "19 19\n",
      "27 27\n",
      "34 34\n",
      "29 29\n",
      "27 27\n",
      "25 25\n",
      "23 24\n",
      "22 22\n",
      "13 13\n",
      "18 18\n",
      "26 26\n",
      "2 2\n",
      "19 6\n",
      "27 27\n",
      "13 13\n",
      "18 18\n",
      "26 26\n",
      "29 29\n",
      "13 13\n",
      "22 13\n",
      "30 30\n",
      "5 5\n",
      "19 19\n",
      "27 27\n",
      "23 2\n",
      "35 35\n",
      "13 13\n",
      "18 16\n",
      "26 22\n",
      "2 2\n",
      "19 13\n",
      "27 18\n",
      "13 27\n",
      "0 0\n",
      "22 13\n",
      "26 26\n",
      "29 29\n",
      "13 13\n",
      "0 0\n",
      "26 26\n",
      "30 30\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actual)):\n",
    "    print(str(actual[i])+' '+str(result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,count=np.unique(actual,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 44 artists>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for: 0 we have: 1\n",
      "for: 1 we have: 1\n",
      "for: 2 we have: 11\n",
      "for: 3 we have: 1\n",
      "for: 4 we have: 1\n",
      "for: 5 we have: 1\n",
      "for: 6 we have: 17\n",
      "for: 7 we have: 2\n",
      "for: 8 we have: 1\n",
      "for: 9 we have: 5\n",
      "for: 10 we have: 1\n",
      "for: 11 we have: 1\n",
      "for: 12 we have: 8\n",
      "for: 13 we have: 7\n",
      "for: 14 we have: 14\n",
      "for: 15 we have: 7\n",
      "for: 16 we have: 1\n",
      "for: 17 we have: 4\n",
      "for: 18 we have: 20\n",
      "for: 19 we have: 1\n",
      "for: 20 we have: 10\n",
      "for: 21 we have: 2\n",
      "for: 22 we have: 17\n",
      "for: 23 we have: 15\n",
      "for: 24 we have: 1\n",
      "for: 25 we have: 26\n",
      "for: 26 we have: 1\n",
      "for: 27 we have: 18\n",
      "for: 28 we have: 1\n",
      "for: 29 we have: 10\n",
      "for: 30 we have: 16\n",
      "for: 31 we have: 1\n",
      "for: 32 we have: 9\n",
      "for: 33 we have: 3\n",
      "for: 34 we have: 11\n",
      "for: 35 we have: 2\n",
      "for: 36 we have: 1\n",
      "for: 37 we have: 5\n",
      "for: 38 we have: 1\n",
      "for: 39 we have: 3\n",
      "for: 40 we have: 1\n",
      "for: 41 we have: 2\n",
      "for: 42 we have: 1\n",
      "for: 43 we have: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(count)):\n",
    "    print('for: '+str(x[i])+' we have: '+str(count[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
