{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install music21\n",
    "!{sys.executable} -m pip install tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n",
    "\n",
    "We write functions to:\n",
    "\n",
    "1- Encode Each song.\n",
    "\n",
    "2- Decode each song and save it as midi.\n",
    "\n",
    "3- Obtain a dict that translates each event into a numerical value.\n",
    "\n",
    "4- Prepare input sequences and outputs for the three LSTMs to be trained.\n",
    "\n",
    "5- Train the LSTMs.\n",
    "\n",
    "6- Use the three trained LSTMs to generate music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harajlim/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(filename):\n",
    "    \"\"\"Encodes song in filename. See milestone1 report for encoding\"\"\"\n",
    "    notesRaw=music21.converter.parse(filename)\n",
    "    notesRaw=notesRaw.flat.notes\n",
    "        \n",
    "    pitches=[]\n",
    "    offsets=[]\n",
    "        \n",
    "    for note in notesRaw:\n",
    "        if isinstance(note,music21.note.Note):\n",
    "            pitches.append(note.pitch.midi)\n",
    "            offsets.append(note.offset)\n",
    "        else:\n",
    "            chordNotes=[int(b.midi) for b in note.pitches]\n",
    "            pitches.extend(chordNotes)\n",
    "            offsets.extend([note.offset]*len(chordNotes))\n",
    "\n",
    "    pitches=np.array(pitches)\n",
    "    offsets=np.array(offsets)\n",
    "    uniqueSortedOffsets=np.sort(np.unique(offsets))\n",
    "    \n",
    "    encoding=[]\n",
    "    \n",
    "    for i in range(len(uniqueSortedOffsets)-1):\n",
    "        time=uniqueSortedOffsets[i]\n",
    "        pitchesHere=pitches[offsets==time]\n",
    "        goforward='gf'+str(uniqueSortedOffsets[i+1]-time)\n",
    "        \n",
    "        encoding.extend(list(np.sort(pitchesHere)))\n",
    "        encoding.append(goforward)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return encoding   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_song(song,filename):\n",
    "    \"\"\"Decodes song encoded by encode_song(). song is an encoded song of type list, and filename is\n",
    "    the path where the new decoded midi file is to reside\"\"\"\n",
    "    stream=[]\n",
    "    offset=0\n",
    "    for event in song:\n",
    "        if 'gf' in str(event):\n",
    "            offset+=float(event[2:])\n",
    "        else:\n",
    "            newNote=music21.note.Note(int(event))\n",
    "            newNote.offset=offset\n",
    "            newNote.storedInstrument=music21.instrument.Piano()\n",
    "            stream.append(newNote)\n",
    "    midi_stream=music21.stream.Stream(stream)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "    return 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get the the directories of all the songs in our dataset. \n",
    "\n",
    "artists=glob.glob('Music/*') #files are sorted via artist\n",
    " \n",
    "songs=[] #the song filename\n",
    "\n",
    "for artist in artists:\n",
    "    songs.extend(glob.glob(artist+'/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 266/266 [28:20<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#we encode each song, save them in a dataframe, and then pickle the dataframe.\n",
    "information=defaultdict(list)\n",
    "\n",
    "for song in tqdm(songs):\n",
    "    encoded=encode_song(song)\n",
    "    _,artist,songname=song.split('\\\\')\n",
    "    information['SongName'].append(songname)\n",
    "    information['Artist'].append(artist)\n",
    "    information['Encoded'].append(encoded)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_to_save=pd.DataFrame.from_dict(information)\n",
    "DF_to_save.head()\n",
    "\n",
    "with open('encodings/information.pickle','wb') as file:\n",
    "    pickle.dump(DF_to_save,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF_to_save\n",
    "DF_to_save=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 266/266 [00:00<00:00, 3410.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#inWhat follows we create three dictionaries: one for notes and gf (which will be used in the input)\n",
    "#another for just gfs (output of get_gf), and another for just notes (for get_note)\n",
    "\n",
    "#we first get all the unique elements of our vocabulary:\n",
    "\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "    \n",
    "notesOnly=[]\n",
    "gfOnly=[]\n",
    "\n",
    "for word in vocab:\n",
    "\n",
    "    if 'gf' in str(word):\n",
    "        gfOnly.append(word)\n",
    "    else:\n",
    "        notesOnly.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check to see what is the quarter lengths duration of the unique go forward events\n",
    "numbers=[]\n",
    "for gf in gfOnly:\n",
    "    if '/' in gf:\n",
    "        num,denom=gf.split('/')\n",
    "        num=num[2:]\n",
    "        numbers.append(float(num)/float(denom))\n",
    "    else:\n",
    "        numbers.append(float(gf[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08333333333325754, 0.08333333333331439, 0.0833333333333286, 0.08333333333333215, 0.08333333333333304, 0.08333333333333326, 0.08333333333333331, 0.08333333333333337, 0.08333333333333348, 0.08333333333333393, 0.0833333333333357, 0.08333333333334281, 0.08333333333337123, 0.16666666666662877, 0.1666666666666572, 0.1666666666666643, 0.16666666666666607, 0.16666666666666652, 0.16666666666666663, 0.16666666666666669, 0.16666666666666674, 0.16666666666666696, 0.16666666666666785, 0.1666666666666714, 0.16666666666668561, 0.16666666666674246, 0.25, 0.33333333333325754, 0.3333333333333144, 0.3333333333333286, 0.33333333333333215, 0.33333333333333304, 0.33333333333333326, 0.3333333333333333, 0.3333333333333333, 0.33333333333333337, 0.3333333333333335, 0.3333333333333339, 0.3333333333333357, 0.3333333333333428, 0.33333333333337123, 0.41666666666662877, 0.4166666666666572, 0.4166666666666643, 0.41666666666666663, 0.41666666666666785, 0.4166666666666714, 0.4166666666666856, 0.5, 0.6666666666666288, 0.6666666666666572, 0.6666666666666643, 0.6666666666666661, 0.6666666666666665, 0.6666666666666666, 0.6666666666666667, 0.666666666666667, 0.6666666666666679, 0.6666666666666714, 0.6666666666666856, 0.6666666666667425, 0.75, 0.8333333333332575, 0.8333333333333144, 0.8333333333333286, 0.8333333333333321, 0.833333333333333, 0.8333333333333339, 0.8333333333333357, 0.8333333333333428, 0.8333333333333712, 0.9166666666666572, 1.0, 1.0, 1.0833333333332575, 1.0833333333333428, 1.1666666666666572, 1.1666666666666643, 1.1666666666666714, 1.1666666666666856, 1.25, 1.3333333333332575, 1.3333333333333144, 1.3333333333333286, 1.3333333333333321, 1.3333333333333428, 1.3333333333333712, 1.416666666666666, 1.5, 1.5833333333333144, 1.583333333333333, 1.6666666666666288, 1.6666666666666572, 1.6666666666666714, 1.6666666666667425, 1.75, 1.8333333333333144, 1.8333333333333357, 2.0, 2.0833333333333144, 2.1666666666666714, 2.25, 2.3333333333332575, 2.3333333333333144, 2.333333333333332, 2.3333333333333357, 2.3333333333333712, 2.5, 2.666666666666657, 2.6666666666666643, 2.6666666666666856, 2.75, 2.8333333333333357, 3.0, 3.25, 3.5, 3.666666666666657, 3.6666666666666643, 3.666666666666666, 3.75, 3.8333333333333144, 4.0, 4.25, 4.5, 4.666666666666686, 4.75, 5.0, 5.333333333333371, 5.5, 5.666666666666664, 5.833333333333371, 6.0, 6.25, 6.5, 7.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we see that alot of the unique offsets are essentially the same but differ slightly due to representation by the author of the midi file. We thus have to fix something in the representation of the gfs. This is something we could have fixed in the encode_song function. However to avoid having to open the files again, we ammend the issue in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 266/266 [00:03<00:00, 76.09it/s]\n"
     ]
    }
   ],
   "source": [
    "NewColumn=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    encoding=DF.iloc[i,2]\n",
    "    #now loop through every word of the encoding\n",
    "    replacement=[]\n",
    "    for i,word in enumerate(encoding):\n",
    "        if 'gf' in str(word):\n",
    "            #we have a gf, we isolate the word from the letters 'gf'\n",
    "            keep=word[2:]\n",
    "            #we now check to see if there is a division symbol:\n",
    "            if '/' in keep:\n",
    "                numerator,denominator=keep.split('/')\n",
    "                keep=np.round(float(numerator)/float(denominator),4)\n",
    "                replacement.append('gf'+str(keep))\n",
    "            else:\n",
    "                replacement.append('gf'+str(np.round(float(keep),4)))\n",
    "                \n",
    "        else:\n",
    "            #its just a note.\n",
    "            replacement.append(word)\n",
    "    NewColumn.append(replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['ModedEncoded']=NewColumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF.drop(columns='Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodings/information.pickle','wb') as file:\n",
    "    pickle.dump(DF,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodings/information.pickle','rb') as file:\n",
    "    DF=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ModedEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alb_esp1.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[57, 81, gf0.5, 64, 88, gf3.25, 62, 86, gf0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alb_esp2.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[38, 50, gf0.75, 57, gf0.25, 62, 66, 69, gf0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alb_esp3.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[59, 71, gf0.5, 63, 75, gf0.5, 66, 78, gf0.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alb_esp4.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[79, gf0.5, 71, 74, gf0.5, 72, 75, gf0.5, 69, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alb_esp5.mid</td>\n",
       "      <td>albeniz</td>\n",
       "      <td>[51, 58, gf0.5, 58, gf1.0, 58, gf0.5, 51, 58, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SongName   Artist                                       ModedEncoded\n",
       "0  alb_esp1.mid  albeniz  [57, 81, gf0.5, 64, 88, gf3.25, 62, 86, gf0.08...\n",
       "1  alb_esp2.mid  albeniz  [38, 50, gf0.75, 57, gf0.25, 62, 66, 69, gf0.5...\n",
       "2  alb_esp3.mid  albeniz  [59, 71, gf0.5, 63, 75, gf0.5, 66, 78, gf0.5, ...\n",
       "3  alb_esp4.mid  albeniz  [79, gf0.5, 71, 74, gf0.5, 72, 75, gf0.5, 69, ...\n",
       "4  alb_esp5.mid  albeniz  [51, 58, gf0.5, 58, gf1.0, 58, gf0.5, 51, 58, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF[DF['Artist']=='chopin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=DF.iloc[[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1719.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#we first get all the unique elements of our vocabulary:\n",
    "\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))\n",
    "    \n",
    "notesOnly=[]\n",
    "gfOnly=[]\n",
    "\n",
    "for word in vocab:\n",
    "\n",
    "    if 'gf' in str(word):\n",
    "        gfOnly.append(word)\n",
    "    else:\n",
    "        notesOnly.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0833,\n",
       " 0.1667,\n",
       " 0.25,\n",
       " 0.3333,\n",
       " 0.4167,\n",
       " 0.5,\n",
       " 0.6667,\n",
       " 0.75,\n",
       " 0.8333,\n",
       " 0.9167,\n",
       " 1.0,\n",
       " 1.0833,\n",
       " 1.1667,\n",
       " 1.25,\n",
       " 1.3333,\n",
       " 1.4167,\n",
       " 1.5,\n",
       " 1.5833,\n",
       " 1.6667,\n",
       " 1.75,\n",
       " 1.8333,\n",
       " 2.0,\n",
       " 2.0833,\n",
       " 2.1667,\n",
       " 2.25,\n",
       " 2.3333,\n",
       " 2.5,\n",
       " 2.6667,\n",
       " 2.75,\n",
       " 2.8333,\n",
       " 3.0,\n",
       " 3.25,\n",
       " 3.5,\n",
       " 3.6667,\n",
       " 3.75,\n",
       " 3.8333,\n",
       " 4.0,\n",
       " 4.25,\n",
       " 4.5,\n",
       " 4.6667,\n",
       " 4.75,\n",
       " 5.0,\n",
       " 5.3333,\n",
       " 5.5,\n",
       " 5.6667,\n",
       " 5.8333,\n",
       " 6.0,\n",
       " 6.25,\n",
       " 6.5,\n",
       " 7.0,\n",
       " 8.0]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check to see what is the quarter lengths duration of the unique go forward events\n",
    "numbers=[]\n",
    "for gf in gfOnly:\n",
    "    if '/' in gf:\n",
    "        num,denom=gf.split('/')\n",
    "        num=num[2:]\n",
    "        numbers.append(float(num)/float(denom))\n",
    "    else:\n",
    "        numbers.append(float(gf[2:]))\n",
    "sorted(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now can start preparing inputs and outputs for the various neural networks we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2006.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#first step is getting a representation of the vocabulary:\n",
    "vocab=[]\n",
    "for i in tqdm(range(len(DF))):\n",
    "    vocab.extend(DF.iloc[i,2])\n",
    "    vocab=list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a dict to translate each vocab element to a number and vice versa:\n",
    "WordToNumber={}\n",
    "NumberToWord={}\n",
    "\n",
    "GfToNumber={}\n",
    "NumberToGf={}\n",
    "\n",
    "NoteToNumber={}\n",
    "NumberToNote={}\n",
    "\n",
    "\n",
    "gf_index=0\n",
    "note_index=0\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    WordToNumber[word]=i\n",
    "    NumberToWord[i]=word\n",
    "    if 'gf' in str(word):\n",
    "        GfToNumber[word]=gf_index\n",
    "        NumberToGf[gf_index]=word\n",
    "        gf_index+=1\n",
    "    else:\n",
    "        NoteToNumber[word]=note_index\n",
    "        NumberToNote[note_index]=word\n",
    "        note_index+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Architecture:\n",
    "\n",
    "We have 3 neural networks:\n",
    "\n",
    "1- gf_or_note\n",
    "\n",
    "2- get_gf\n",
    "\n",
    "3- get_note\n",
    "\n",
    "\n",
    "\n",
    "The inputs for all three of the nets are in the same space and have the same representation. The outputs differ. The output of gf_or_note is binary, the output of get_gf is limited to the different available gf's while the output of get_note is limited to the keys on the piano.\n",
    "\n",
    "We begin by getting a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_gf_or_note(DF, n_vocab,WordToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            if 'gf' not in str(sequence_in[-1]):\n",
    "                sequence_out = float('gf' in str(song[i + sequence_length]))\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(sequence_out)\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 269.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 100, 1)\n",
      "(264, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_gf_or_note(DF,len(WordToNumber),WordToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_gf(DF, n_vocab,WordToNumber,GfToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(GfToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 199.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 100, 1)\n",
      "(161, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_get_gf(DF,len(WordToNumber),WordToNumber,GfToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_get_note(DF, n_vocab,WordToNumber,NoteToNumber,sequence_length=100): \n",
    "    \"\"\"Given a list of locations for all the midi files in the dataset, this function encodes each song\"\"\"\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in tqdm(range(len(DF))):\n",
    "        song=DF.iloc[i,2]\n",
    "        # create input sequences and the corresponding outputs\n",
    "        \n",
    "        for i in range(0, len(song) - sequence_length, 1):\n",
    "            #we only use the sequence if the last event is not a gf event:\n",
    "            sequence_in = song[i: i + sequence_length]\n",
    "            sequence_out=song[i + sequence_length]\n",
    "            if 'gf' not in str(sequence_out):\n",
    "                network_input.append([WordToNumber[char] for char in sequence_in])\n",
    "                network_output.append(NoteToNumber[sequence_out])\n",
    "                \n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 182.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 100, 1)\n",
      "(263, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inp,out=prepare_sequences_get_note(DF,len(WordToNumber),WordToNumber,NoteToNumber)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_gf_or_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_gf(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_get_note(network_in, n_vocab_out): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab_out))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def train_gf_or_note(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.gf_or_note.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_get_gf(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.get_gf.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_get_note(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'SavedModels/weights.get_note.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=10000, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 123.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 241.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences Prepared, creating models\n",
      "Models Created, training in progress\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 2s 8ms/step - loss: 0.6976\n",
      "Epoch 1/1\n",
      "161/161 [==============================] - 2s 13ms/step - loss: 1.0964\n",
      "Epoch 1/1\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.7744\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "\n",
    "gf_or_note_input,gf_or_note_output=prepare_sequences_gf_or_note(DF,len(WordToNumber),WordToNumber)\n",
    "get_gf_input,get_gf_output=prepare_sequences_get_gf(DF,len(WordToNumber),WordToNumber,GfToNumber)\n",
    "get_note_input,get_note_output=prepare_sequences_get_note(DF,len(WordToNumber),WordToNumber,NoteToNumber)\n",
    "\n",
    "print('Sequences Prepared, creating models')\n",
    "\n",
    "gf_or_note=create_network_gf_or_note(gf_or_note_input,gf_or_note_output.shape[1])\n",
    "get_gf=create_network_get_gf(get_gf_input,get_gf_output.shape[1])\n",
    "get_note=create_network_get_note(get_note_input,get_note_output.shape[1])\n",
    "\n",
    "print('Models Created, training in progress')\n",
    "\n",
    "train_gf_or_note(gf_or_note,gf_or_note_input,gf_or_note_output,epochs)\n",
    "train_get_gf(get_gf,get_gf_input,get_gf_output,epochs)\n",
    "train_get_note(get_note,get_note_input,get_note_output,epochs)\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
